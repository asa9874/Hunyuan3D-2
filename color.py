import torch
import os
import time
from datetime import datetime
from PIL import Image
from hy3dgen.texgen import Hunyuan3DPaintPipeline
from hy3dgen.shapegen import Hunyuan3DDiTFlowMatchingPipeline
from hy3dgen.rembg import BackgroundRemover

# ==== ì„¤ì • ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ ====
# ê²½ë¡œ ì„¤ì •
INPUT_IMAGE = 'my/input/shirts.jpg'     # ì…ë ¥ ì´ë¯¸ì§€ ê²½ë¡œ

# ë°°ê²½ ì œê±° ì„¤ì •
REMOVE_BACKGROUND = True            # ë°°ê²½ ì œê±° í™œì„±í™” (True/False)

# í˜•ìƒ ìƒì„± í’ˆì§ˆ ì„¤ì •
NUM_INFERENCE_STEPS = 5             # í˜•ìƒ ìƒì„± ì¶”ë¡  ë‹¨ê³„ (ê¸°ë³¸: 5, ë²”ìœ„: 3-10)
OCTREE_RESOLUTION = 192             # Octree í•´ìƒë„ (128=ë¹ ë¦„/ë‚®ì€í’ˆì§ˆ, 192=ê· í˜•, 256=ëŠë¦¼/ë†’ì€í’ˆì§ˆ)
GUIDANCE_SCALE = 5                  # ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼ (ê¸°ë³¸: 5, ë²”ìœ„: 3-10)

# í…ìŠ¤ì²˜ ìƒì„± í’ˆì§ˆ ì„¤ì •
DELIGHT_INFERENCE_STEPS = 6         # ê·¸ë¦¼ì ì œê±° ì¶”ë¡  ë‹¨ê³„ (ê¸°ë³¸: 6, ë²”ìœ„: 4-10)
MULTIVIEW_INFERENCE_STEPS = 6       # ë©€í‹°ë·° ìƒì„± ì¶”ë¡  ë‹¨ê³„ (ê¸°ë³¸: 6, ë²”ìœ„: 4-10)

# ì¹´ë©”ë¼ ë·° ì„¤ì • (ì†ë„ ìµœì í™”)
CAMERA_VIEWS = 'standard'           # 'standard'(6ë·°,ëŠë¦¼), 'fast'(4ë·°,ë¹ ë¦„), 'minimal'(3ë·°,ë§¤ìš°ë¹ ë¦„)

# ë Œë”ë§ ì„¤ì •
RENDER_SIZE = 2048                  # ë Œë” í•´ìƒë„ (1024=ë¹ ë¦„, 2048=ê¸°ë³¸, 4096=ê³ í’ˆì§ˆ/ëŠë¦¼)
TEXTURE_SIZE = 2048                 # í…ìŠ¤ì²˜ í•´ìƒë„ (1024, 2048, 4096)
# ============================

# ì¶œë ¥ íŒŒì¼ëª…ì„ ì…ë ¥ íŒŒì¼ëª…ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì • (í™•ì¥ìë§Œ .glbë¡œ ë³€ê²½)
input_filename = os.path.splitext(os.path.basename(INPUT_IMAGE))[0]
OUTPUT_PATH = f'my/output/{input_filename}.glb'

# ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
log_dir = 'my/log'
os.makedirs(log_dir, exist_ok=True)
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
LOG_PATH = os.path.join(log_dir, f'{timestamp}_{input_filename}.txt')

# ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ë³€ìˆ˜
time_records = {}
start_total = time.time()  # ì „ì²´ ì‹œì‘ ì‹œê°„

# 0. ì´ë¯¸ì§€ ë¡œë“œ ë° ë°°ê²½ ì œê±° (í•„ìš”ì‹œ)
print("=" * 60)
print("ì…ë ¥ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
print(f"  - ì…ë ¥ ì´ë¯¸ì§€: {INPUT_IMAGE}")
start_time = time.time()

# ì›ë³¸ ì´ë¯¸ì§€ ëª¨ë“œ í™•ì¸ (ë³€í™˜ ì „)
image = Image.open(INPUT_IMAGE)
original_mode = image.mode
print(f"  - ì›ë³¸ ì´ë¯¸ì§€ ëª¨ë“œ: {original_mode}")

# ë°°ê²½ ì œê±° ìˆ˜í–‰ ì—¬ë¶€ ê²°ì •
if REMOVE_BACKGROUND and original_mode in ['RGB', 'L']:  # RGB ë˜ëŠ” ê·¸ë ˆì´ìŠ¤ì¼€ì¼ì¸ ê²½ìš°
    print("  - ë°°ê²½ì´ ìˆëŠ” ì´ë¯¸ì§€ì…ë‹ˆë‹¤. ë°°ê²½ ì œê±°ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
    if original_mode == 'L':
        image = image.convert('RGB')
    rembg = BackgroundRemover()
    image = rembg(image)
    print("  - ë°°ê²½ ì œê±° ì™„ë£Œ! (RGBAë¡œ ë³€í™˜ë¨)")
elif REMOVE_BACKGROUND and original_mode == 'RGBA':
    print("  - ì´ë¯¸ì§€ì— ì´ë¯¸ ì•ŒíŒŒ ì±„ë„(íˆ¬ëª…ë„)ì´ ìˆì–´ ë°°ê²½ ì œê±°ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
elif not REMOVE_BACKGROUND:
    print("  - ë°°ê²½ ì œê±°ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    image = image.convert("RGBA")
else:
    image = image.convert("RGBA")

time_records['ì´ë¯¸ì§€ ì „ì²˜ë¦¬'] = time.time() - start_time
print(f"ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time_records['ì´ë¯¸ì§€ ì „ì²˜ë¦¬']:.2f}ì´ˆ)")
print("=" * 60)

# 1. í˜•ìƒ(Shape) ìƒì„± íŒŒì´í”„ë¼ì¸ ë¡œë“œ
print("=" * 60)
print("í˜•ìƒ ìƒì„± íŒŒì´í”„ë¼ì¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
start_time = time.time()
shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(
    'tencent/Hunyuan3D-2',
    subfolder='hunyuan3d-dit-v2-0-turbo',
    torch_dtype=torch.float16
)
shape_pipeline.to('cuda')
time_records['íŒŒì´í”„ë¼ì¸ ë¡œë“œ'] = time.time() - start_time
print(f"ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time_records['íŒŒì´í”„ë¼ì¸ ë¡œë“œ']:.2f}ì´ˆ)")
print("=" * 60)

print("=" * 60)
print(f"ì´ë¯¸ì§€ë¡œë¶€í„° 3D ëª¨ë¸ í˜•ìƒì„ ìƒì„±í•©ë‹ˆë‹¤...")
print(f"  - ì¶”ë¡  ë‹¨ê³„: {NUM_INFERENCE_STEPS}")
print(f"  - í•´ìƒë„: {OCTREE_RESOLUTION}")
print(f"  - ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼: {GUIDANCE_SCALE}")
start_time = time.time()
# shape_pipelineì˜ ê²°ê³¼ëŠ” ë¦¬ìŠ¤íŠ¸ì´ë¯€ë¡œ, [0]ì„ ë¶™ì—¬ ì²« ë²ˆì§¸ ëª¨ë¸ ê°ì²´ë¥¼ êº¼ëƒ…ë‹ˆë‹¤.
mesh = shape_pipeline(
    image=image,  # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì‚¬ìš©
    num_inference_steps=NUM_INFERENCE_STEPS,
    octree_resolution=OCTREE_RESOLUTION,
    guidance_scale=GUIDANCE_SCALE
)[0]
time_records['í˜•ìƒ ìƒì„±'] = time.time() - start_time
print(f"í˜•ìƒ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! (ì†Œìš” ì‹œê°„: {time_records['í˜•ìƒ ìƒì„±']:.2f}ì´ˆ)")
print("=" * 60)

# 2. í…ìŠ¤ì²˜(Texture) ìƒì„± íŒŒì´í”„ë¼ì¸ ë¡œë“œ
print("\ní…ìŠ¤ì²˜ ìƒì„± íŒŒì´í”„ë¼ì¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
start_time = time.time()

# ì¹´ë©”ë¼ ë·° ì„¤ì •
if CAMERA_VIEWS == 'minimal':
    camera_azims = [0, 120, 240]  # 3ë·°: ì •ë©´, ì¢Œì¸¡ 120ë„, ìš°ì¸¡ 120ë„
    camera_elevs = [0, 0, 0]
    view_weights = [1, 0.3, 0.3]
    print(f"  - ì¹´ë©”ë¼ ë·°: ìµœì†Œ (3ë·°, ë§¤ìš° ë¹ ë¦„)")
elif CAMERA_VIEWS == 'fast':
    camera_azims = [0, 90, 180, 270]  # 4ë·°: ì „í›„ì¢Œìš°
    camera_elevs = [0, 0, 0, 0]
    view_weights = [1, 0.1, 0.5, 0.1]
    print(f"  - ì¹´ë©”ë¼ ë·°: ë¹ ë¦„ (4ë·°)")
else:  # standard
    camera_azims = [0, 90, 180, 270, 0, 180]  # 6ë·°: ì „í›„ì¢Œìš° + ìœ„ì•„ë˜
    camera_elevs = [0, 0, 0, 0, 90, -90]
    view_weights = [1, 0.1, 0.5, 0.1, 0.05, 0.05]
    print(f"  - ì¹´ë©”ë¼ ë·°: í‘œì¤€ (6ë·°)")

# íŒŒì´í”„ë¼ì¸ ì„¤ì •ì„ ìœ„í•œ ì»¤ìŠ¤í…€ config í´ë˜ìŠ¤
class CustomTexGenConfig:
    def __init__(self, light_remover_ckpt_path, multiview_ckpt_path, subfolder_name):
        self.device = 'cuda'
        self.light_remover_ckpt_path = light_remover_ckpt_path
        self.multiview_ckpt_path = multiview_ckpt_path
        self.candidate_camera_azims = camera_azims
        self.candidate_camera_elevs = camera_elevs
        self.candidate_view_weights = view_weights
        self.render_size = RENDER_SIZE
        self.texture_size = TEXTURE_SIZE
        self.delight_inference_steps = DELIGHT_INFERENCE_STEPS  # ì¶”ê°€
        self.multiview_inference_steps = MULTIVIEW_INFERENCE_STEPS  # ì¶”ê°€
        self.bake_exp = 4
        self.merge_method = 'fast'
        self.pipe_dict = {'hunyuan3d-paint-v2-0': 'hunyuanpaint', 'hunyuan3d-paint-v2-0-turbo': 'hunyuanpaint-turbo'}
        self.pipe_name = self.pipe_dict[subfolder_name]

# ì›ë˜ config í´ë˜ìŠ¤ë¥¼ ì„ì‹œë¡œ êµì²´
import hy3dgen.texgen.pipelines as texgen_module
original_config = texgen_module.Hunyuan3DTexGenConfig
texgen_module.Hunyuan3DTexGenConfig = CustomTexGenConfig

paint_pipeline = Hunyuan3DPaintPipeline.from_pretrained(
    'tencent/Hunyuan3D-2',
    subfolder='hunyuan3d-paint-v2-0-turbo'
)

# ì›ë˜ config ë³µì›
texgen_module.Hunyuan3DTexGenConfig = original_config

# âš¡ ì¤‘ìš”: í…ìŠ¤ì²˜ ìƒì„± ëª¨ë¸ë“¤ì„ GPUë¡œ ì´ë™ (ì„±ëŠ¥ í–¥ìƒ)
print("  - ëª¨ë¸ì„ GPUë¡œ ì´ë™ ì¤‘...")
paint_pipeline.models['delight_model'].pipeline.to('cuda')
paint_pipeline.models['multiview_model'].pipeline.to('cuda')
paint_pipeline.render.device = torch.device('cuda')

# GPU ìƒíƒœ í™•ì¸
gpu_status_lines = []
gpu_status_lines.append("ğŸ“Š GPU ìƒíƒœ í™•ì¸:")
try:
    # Diffusers íŒŒì´í”„ë¼ì¸ì˜ ë‚´ë¶€ ëª¨ë¸ í™•ì¸
    delight_device = paint_pipeline.models['delight_model'].pipeline.unet.device
    multiview_device = paint_pipeline.models['multiview_model'].pipeline.unet.device
    gpu_status_lines.append(f"    - delight_model ë””ë°”ì´ìŠ¤: {delight_device}")
    gpu_status_lines.append(f"    - multiview_model ë””ë°”ì´ìŠ¤: {multiview_device}")
except:
    gpu_status_lines.append(f"    - ë””ë°”ì´ìŠ¤ í™•ì¸ ì‹¤íŒ¨ (í•˜ì§€ë§Œ .to('cuda') í˜¸ì¶œì€ ì™„ë£Œë¨)")
gpu_status_lines.append(f"    - render ë””ë°”ì´ìŠ¤: {paint_pipeline.render.device}")
if torch.cuda.is_available():
    gpu_mem = torch.cuda.memory_allocated() / 1024**3
    gpu_mem_reserved = torch.cuda.memory_reserved() / 1024**3
    gpu_status_lines.append(f"    - GPU ë©”ëª¨ë¦¬ ì‚¬ìš©: {gpu_mem:.2f} GB")
    gpu_status_lines.append(f"    - GPU ë©”ëª¨ë¦¬ ì˜ˆì•½: {gpu_mem_reserved:.2f} GB")

# ì½˜ì†”ì— ì¶œë ¥
print("\n  " + "\n  ".join(gpu_status_lines))

time_records['í…ìŠ¤ì²˜ íŒŒì´í”„ë¼ì¸ ë¡œë“œ'] = time.time() - start_time
print(f"\nì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time_records['í…ìŠ¤ì²˜ íŒŒì´í”„ë¼ì¸ ë¡œë“œ']:.2f}ì´ˆ)")

print("=" * 60)
print("ëª¨ë¸ì— í…ìŠ¤ì²˜ë¥¼ ì…í™ë‹ˆë‹¤...")
if torch.cuda.is_available():
    gpu_mem_before = torch.cuda.memory_allocated() / 1024**3
    print(f"  - ì‹œì‘ ì „ GPU ë©”ëª¨ë¦¬: {gpu_mem_before:.2f} GB")
start_time = time.time()
mesh_textured = paint_pipeline(mesh, image=image)  # ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ ì‚¬ìš©
time_records['í…ìŠ¤ì²˜ ìƒì„±'] = time.time() - start_time

# í…ìŠ¤ì²˜ ìƒì„± í”„ë¡œíŒŒì¼ë§ ê²°ê³¼ ì €ì¥
texture_profiling = getattr(paint_pipeline, 'profiling', {})

if torch.cuda.is_available():
    gpu_mem_after = torch.cuda.memory_allocated() / 1024**3
    print(f"  - ì™„ë£Œ í›„ GPU ë©”ëª¨ë¦¬: {gpu_mem_after:.2f} GB (ë³€í™”: {gpu_mem_after - gpu_mem_before:+.2f} GB)")
print(f"í…ìŠ¤ì²˜ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! (ì†Œìš” ì‹œê°„: {time_records['í…ìŠ¤ì²˜ ìƒì„±']:.2f}ì´ˆ)")
print("=" * 60)

# 3. ìµœì¢… ê²°ê³¼ë¬¼ ì €ì¥
print("\nìµœì¢… ê²°ê³¼ë¬¼ì„ ì €ì¥í•©ë‹ˆë‹¤...")
start_time = time.time()
mesh_textured.export(OUTPUT_PATH)
time_records['íŒŒì¼ ì €ì¥'] = time.time() - start_time
print(f"ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time_records['íŒŒì¼ ì €ì¥']:.2f}ì´ˆ)")

# 4. ì „ì²´ ì†Œìš” ì‹œê°„ ì¶œë ¥ ë° ë¡œê·¸ ì €ì¥
print("\n" + "=" * 60)
print("ğŸ“Š ì²˜ë¦¬ ì‹œê°„ ìš”ì•½")
print("=" * 60)
total_time = time.time() - start_total
for step, elapsed in time_records.items():
    percentage = (elapsed / total_time) * 100
    print(f"  {step:20s}: {elapsed:6.2f}ì´ˆ ({percentage:5.1f}%)")
print("-" * 60)
print(f"  {'ì´ ì†Œìš” ì‹œê°„':20s}: {total_time:6.2f}ì´ˆ")
print("=" * 60)

# 5. ì‚¬ìš©ëœ ì„¤ì •ê°’ ì¶œë ¥
print("\n" + "=" * 60)
print("âš™ï¸  ì‚¬ìš©ëœ ì„¤ì •ê°’")
print("=" * 60)
print(f"  ì…ë ¥ ì´ë¯¸ì§€         : {INPUT_IMAGE}")
print(f"  ì¶œë ¥ íŒŒì¼          : {OUTPUT_PATH}")
print(f"  ë°°ê²½ ì œê±°          : {'í™œì„±í™”' if REMOVE_BACKGROUND else 'ë¹„í™œì„±í™”'}")
print("-" * 60)
print("  [í˜•ìƒ ìƒì„±]")
print(f"    ì¶”ë¡  ë‹¨ê³„         : {NUM_INFERENCE_STEPS}")
print(f"    Octree í•´ìƒë„     : {OCTREE_RESOLUTION}")
print(f"    ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼    : {GUIDANCE_SCALE}")
print("-" * 60)
print("  [í…ìŠ¤ì²˜ ìƒì„±]")
print(f"    Delight ì¶”ë¡  ë‹¨ê³„ : {DELIGHT_INFERENCE_STEPS}")
print(f"    Multiview ì¶”ë¡  ë‹¨ê³„: {MULTIVIEW_INFERENCE_STEPS}")
print(f"    ì¹´ë©”ë¼ ë·° ëª¨ë“œ     : {CAMERA_VIEWS}")
print(f"    ë Œë” í•´ìƒë„       : {RENDER_SIZE} x {RENDER_SIZE}")
print(f"    í…ìŠ¤ì²˜ í•´ìƒë„      : {TEXTURE_SIZE} x {TEXTURE_SIZE}")
print("=" * 60)
print(f"\nâœ… í…ìŠ¤ì²˜ê°€ ì ìš©ëœ ëª¨ë¸ì´ '{OUTPUT_PATH}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
print("=" * 60)

# 6. ë¡œê·¸ íŒŒì¼ ì €ì¥
log_content = []
log_content.append("=" * 60)
log_content.append("Hunyuan3D-2 3D ëª¨ë¸ ìƒì„± ë¡œê·¸")
log_content.append("=" * 60)
log_content.append(f"ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
log_content.append("")

# GPU ìƒíƒœ ì •ë³´ ì¶”ê°€
log_content.append("=" * 60)
log_content.extend(gpu_status_lines)
log_content.append("=" * 60)
log_content.append("")

# í…ìŠ¤ì²˜ ìƒì„± ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´ ì¶”ê°€
if texture_profiling:
    log_content.append("=" * 60)
    log_content.append("ğŸ” í…ìŠ¤ì²˜ ìƒì„± ë‹¨ê³„ë³„ ì‹œê°„ ë¶„ì„")
    log_content.append("=" * 60)
    for step_name, step_time in texture_profiling.items():
        if step_name != 'TOTAL':
            percentage = (step_time / texture_profiling.get('TOTAL', 1)) * 100
            log_content.append(f"  {step_name:25s}: {step_time:7.2f}ì´ˆ ({percentage:5.1f}%)")
    log_content.append("-" * 60)
    log_content.append(f"  {'TOTAL':25s}: {texture_profiling.get('TOTAL', 0):7.2f}ì´ˆ")
    log_content.append("=" * 60)
    log_content.append("")

log_content.append("=" * 60)
log_content.append("ğŸ“Š ì²˜ë¦¬ ì‹œê°„ ìš”ì•½")
log_content.append("=" * 60)
for step, elapsed in time_records.items():
    percentage = (elapsed / total_time) * 100
    log_content.append(f"  {step:20s}: {elapsed:6.2f}ì´ˆ ({percentage:5.1f}%)")
log_content.append("-" * 60)
log_content.append(f"  {'ì´ ì†Œìš” ì‹œê°„':20s}: {total_time:6.2f}ì´ˆ")
log_content.append("=" * 60)
log_content.append("")
log_content.append("=" * 60)
log_content.append("âš™ï¸  ì‚¬ìš©ëœ ì„¤ì •ê°’")
log_content.append("=" * 60)
log_content.append(f"  ì…ë ¥ ì´ë¯¸ì§€         : {INPUT_IMAGE}")
log_content.append(f"  ì¶œë ¥ íŒŒì¼          : {OUTPUT_PATH}")
log_content.append(f"  ë°°ê²½ ì œê±°          : {'í™œì„±í™”' if REMOVE_BACKGROUND else 'ë¹„í™œì„±í™”'}")
log_content.append("-" * 60)
log_content.append("  [í˜•ìƒ ìƒì„±]")
log_content.append(f"    ì¶”ë¡  ë‹¨ê³„         : {NUM_INFERENCE_STEPS}")
log_content.append(f"    Octree í•´ìƒë„     : {OCTREE_RESOLUTION}")
log_content.append(f"    ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼    : {GUIDANCE_SCALE}")
log_content.append("-" * 60)
log_content.append("  [í…ìŠ¤ì²˜ ìƒì„±]")
log_content.append(f"    Delight ì¶”ë¡  ë‹¨ê³„ : {DELIGHT_INFERENCE_STEPS}")
log_content.append(f"    Multiview ì¶”ë¡  ë‹¨ê³„: {MULTIVIEW_INFERENCE_STEPS}")
log_content.append(f"    ì¹´ë©”ë¼ ë·° ëª¨ë“œ     : {CAMERA_VIEWS}")
log_content.append(f"    ë Œë” í•´ìƒë„       : {RENDER_SIZE} x {RENDER_SIZE}")
log_content.append(f"    í…ìŠ¤ì²˜ í•´ìƒë„      : {TEXTURE_SIZE} x {TEXTURE_SIZE}")
log_content.append("=" * 60)

with open(LOG_PATH, 'w', encoding='utf-8') as f:
    f.write('\n'.join(log_content))

print(f"\nğŸ“ ë¡œê·¸ íŒŒì¼ì´ '{LOG_PATH}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")