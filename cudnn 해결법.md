# cuDNN í™œì„±í™” ë° 8GB VRAM ìµœì í™” ê°€ì´ë“œ

## ğŸ¯ ëª©í‘œ
**`torch.backends.cudnn.enabled = False`ë¥¼ `True`ë¡œ ë³€ê²½í•˜ê³  8GB VRAMì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ì‹¤í–‰**

---

## ğŸ“‹ í˜„ì¬ ë¬¸ì œ ë¶„ì„

### ì™œ cuDNNì„ ë¹„í™œì„±í™”í–ˆë‚˜?

```python
torch.backends.cudnn.enabled = False  # cuDNN ë¹„í™œì„±í™”
```

**ë¹„í™œì„±í™” ì´ìœ **:
1. **ì´ˆê¸°í™” ì˜¤ë¥˜**: cuDNN ë²„ì „ ë¶ˆì¼ì¹˜
2. **ë©”ëª¨ë¦¬ ë¬¸ì œ**: cuDNNì´ ì¶”ê°€ ë©”ëª¨ë¦¬ ì‚¬ìš©
3. **ì•ˆì •ì„±**: ì¼ë¶€ ì—°ì‚°ì—ì„œ ì—ëŸ¬ ë°œìƒ

**ë¹„í™œì„±í™”ì˜ ë¬¸ì œì **:
- âŒ **ì†ë„ ì €í•˜**: 30-50% ëŠë¦¼
- âŒ **ìµœì í™” ë¶€ì¬**: GPU íš¨ìœ¨ ê°ì†Œ
- âŒ **ë©”ëª¨ë¦¬ ë¹„íš¨ìœ¨**: ì—­ì„¤ì ìœ¼ë¡œ ë” ë§ì€ ë©”ëª¨ë¦¬ ì‚¬ìš© ê°€ëŠ¥

---

## ğŸš€ cuDNN í™œì„±í™” ì „ëµ (8GB VRAM)

### ë°©ì•ˆ 1: **Deterministic ëª¨ë“œ (ê¶Œì¥)** â­â­â­

#### ë¬¸ì œ ì›ì¸
cuDNNì˜ ë¹„ê²°ì •ì (non-deterministic) ì•Œê³ ë¦¬ì¦˜ì´ 8GBì—ì„œ ë¶ˆì•ˆì •

#### í•´ê²°ì±…: ê²°ì •ì  ì•Œê³ ë¦¬ì¦˜ ê°•ì œ

```python
# color.py ë˜ëŠ” multiview.py ìµœìƒë‹¨ì— ì¶”ê°€

import torch
import os

# âœ… cuDNN ì•ˆì „ í™œì„±í™” ì„¤ì •
torch.backends.cudnn.enabled = True              # cuDNN í™œì„±í™”
torch.backends.cudnn.benchmark = False           # ë²¤ì¹˜ë§ˆí¬ ë¹„í™œì„±í™” (ë©”ëª¨ë¦¬ ì•ˆì •)
torch.backends.cudnn.deterministic = True        # ê²°ì •ì  ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©

# âœ… ì¶”ê°€ ì•ˆì •í™” ì„¤ì •
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'  # cuBLAS ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì œí•œ
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'           # ë™ê¸°í™” ëª¨ë“œ
torch.use_deterministic_algorithms(True, warn_only=True)  # ê²½ê³ ë§Œ ì¶œë ¥

# âœ… TF32 ì •ë°€ë„ ì¡°ì • (ë©”ëª¨ë¦¬ ì ˆì•½)
torch.backends.cuda.matmul.allow_tf32 = True      # í–‰ë ¬ ì—°ì‚° TF32
torch.backends.cudnn.allow_tf32 = True            # cuDNN ì—°ì‚° TF32

print("âœ… cuDNN ì•ˆì „ ëª¨ë“œ í™œì„±í™” ì™„ë£Œ")
print(f"   - cuDNN í™œì„±í™”: {torch.backends.cudnn.enabled}")
print(f"   - Deterministic: {torch.backends.cudnn.deterministic}")
print(f"   - Benchmark: {torch.backends.cudnn.benchmark}")
```

**ì˜ˆìƒ íš¨ê³¼**:
- ì†ë„: **30-40% í–¥ìƒ** (False ëŒ€ë¹„)
- ì•ˆì •ì„±: ë§¤ìš° ë†’ìŒ
- ë©”ëª¨ë¦¬: ì•½ê°„ ì¦ê°€ (+0.5GB)

---

### ë°©ì•ˆ 2: **Workspace ë©”ëª¨ë¦¬ ì œí•œ** â­â­â­

#### cuDNN ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì œí•œ

```python
# color.py ë˜ëŠ” multiview.pyì— ì¶”ê°€

import torch
import os

# âœ… cuDNN ë©”ëª¨ë¦¬ ì œí•œ (8GB ìµœì í™”)
os.environ['CUDNN_CONV_WORKSPACE_LIMIT'] = '512'  # 512MB ì œí•œ

# âœ… cuDNN í™œì„±í™”
torch.backends.cudnn.enabled = True
torch.backends.cudnn.benchmark = False
torch.backends.cudnn.deterministic = True

# âœ… PyTorch ë©”ëª¨ë¦¬ í• ë‹¹ ì „ëµ
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'

print(f"âœ… cuDNN ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì œí•œ: 512MB")
```

**ì˜ˆìƒ íš¨ê³¼**:
- ë©”ëª¨ë¦¬: **-1 GB** (cuDNN ì›Œí¬ìŠ¤í˜ì´ìŠ¤)
- ì†ë„: ì•½ê°„ ëŠë¦¼ (5-10%)
- ì•ˆì •ì„±: ë§¤ìš° ë†’ìŒ

---

### ë°©ì•ˆ 3: **ì ì§„ì  ë©”ëª¨ë¦¬ í• ë‹¹** â­â­

#### cuDNN ë©”ëª¨ë¦¬ ì¦ê°€ ë°©ì§€

```python
# color.py ë˜ëŠ” multiview.pyì— ì¶”ê°€

import torch
import os

# âœ… cuDNN ë©”ëª¨ë¦¬ ì¦ê°€ ë°©ì§€
torch.backends.cudnn.enabled = True
torch.backends.cudnn.benchmark = False           # ì¤‘ìš”!
torch.backends.cudnn.deterministic = True

# âœ… PyTorch ë©”ëª¨ë¦¬ ì¦ê°€ ë°©ì§€
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'

# âœ… ë©”ëª¨ë¦¬ ë‹¨í¸í™” ë°©ì§€
torch.cuda.empty_cache()
torch.cuda.reset_peak_memory_stats()

print("âœ… cuDNN ì ì§„ì  ë©”ëª¨ë¦¬ í• ë‹¹ í™œì„±í™”")
```

**ì˜ˆìƒ íš¨ê³¼**:
- ë©”ëª¨ë¦¬ ë‹¨í¸í™”: ë°©ì§€
- OOM ì—ëŸ¬: ê°ì†Œ
- ì†ë„: ì˜í–¥ ì—†ìŒ

---

### ë°©ì•ˆ 4: **Mixed Precision + cuDNN** â­â­â­

#### cuDNNê³¼ ìë™ ìºìŠ¤íŒ… ì¡°í•©

```python
# hy3dgen/texgen/pipelines.py ìˆ˜ì •

@torch.no_grad()
def __call__(self, mesh, image):
    import time
    profiling = {}
    total_start = time.time()

    if not isinstance(image, List):
        image = [image]

    # ... ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ...

    # âœ… cuDNN + Autocast ì¡°í•©
    with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16):
        # Delight ëª¨ë¸
        step_start = time.time()
        print("    â†’ [2/11] Delight ëª¨ë¸ ì‹¤í–‰ ì¤‘...")
        images_prompt = [self.models['delight_model'](img) for img in images_prompt]
        profiling['2_delight_model'] = time.time() - step_start
        
        # âœ… ë©”ëª¨ë¦¬ ì •ë¦¬ (cuDNN ìºì‹œ)
        torch.cuda.empty_cache()

    # ... UV, ë Œë”ë§ ...

    with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16):
        # Multiview ëª¨ë¸
        step_start = time.time()
        print("    â†’ [7/11] Multiview ëª¨ë¸ ì‹¤í–‰ ì¤‘...")
        camera_info = [...]
        multiviews = self.models['multiview_model'](
            images_prompt, normal_maps + position_maps, camera_info)
        profiling['7_multiview_model'] = time.time() - step_start
        
        # âœ… ë©”ëª¨ë¦¬ ì •ë¦¬
        torch.cuda.empty_cache()

    # ... ë‚˜ë¨¸ì§€ ë‹¨ê³„ë“¤ ...
```

**ì˜ˆìƒ íš¨ê³¼**:
- ë©”ëª¨ë¦¬: **-2 GB** (float16 + cuDNN ìµœì í™”)
- ì†ë„: **40-50% í–¥ìƒ**
- í’ˆì§ˆ: ì˜í–¥ ì—†ìŒ

---

### ë°©ì•ˆ 5: **cuDNN Algorithm Selection** â­â­

#### ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ

```python
# color.py ë˜ëŠ” multiview.pyì— ì¶”ê°€

import torch
import os

# âœ… cuDNN ì•Œê³ ë¦¬ì¦˜ ì„ íƒ ì „ëµ
torch.backends.cudnn.enabled = True
torch.backends.cudnn.benchmark = False  # ìë™ ì„ íƒ ë¹„í™œì„±í™”

# âœ… ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì•Œê³ ë¦¬ì¦˜ ê°•ì œ
# (benchmark=Falseë©´ ê¸°ë³¸ì ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš©)

def set_cudnn_for_low_memory():
    """8GB VRAMìš© cuDNN ì„¤ì •"""
    torch.backends.cudnn.enabled = True
    torch.backends.cudnn.benchmark = False
    torch.backends.cudnn.deterministic = True
    
    # âœ… ì»¨ë³¼ë£¨ì…˜ ì•Œê³ ë¦¬ì¦˜ íŒíŠ¸
    # (PyTorchê°€ ìë™ìœ¼ë¡œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì•Œê³ ë¦¬ì¦˜ ì„ íƒ)
    os.environ['CUDNN_CONV_USE_MAX_WORKSPACE'] = '0'
    
    print("âœ… cuDNN ì €ë©”ëª¨ë¦¬ ëª¨ë“œ ì„¤ì • ì™„ë£Œ")

set_cudnn_for_low_memory()
```

**ì˜ˆìƒ íš¨ê³¼**:
- ë©”ëª¨ë¦¬: ìµœì†Œí™”
- ì†ë„: benchmark ëŒ€ë¹„ 10-15% ëŠë¦¼ (í•˜ì§€ë§Œ False ëŒ€ë¹„ ë¹ ë¦„)

---

## ğŸ“‹ í†µí•© ì†”ë£¨ì…˜: 8GB VRAM + cuDNN í™œì„±í™”

### ì™„ì „í•œ color.py ì„¤ì •

```python
import torch
import os
import time
from datetime import datetime
from PIL import Image
from hy3dgen.texgen import Hunyuan3DPaintPipeline
from hy3dgen.shapegen import Hunyuan3DDiTFlowMatchingPipeline
from hy3dgen.rembg import BackgroundRemover

# ============================================================
# âœ… cuDNN í™œì„±í™” + 8GB VRAM ìµœì í™” ì„¤ì •
# ============================================================

# 1. cuDNN ì•ˆì „ í™œì„±í™”
torch.backends.cudnn.enabled = True              # âœ… Trueë¡œ ë³€ê²½!
torch.backends.cudnn.benchmark = False           # ë©”ëª¨ë¦¬ ì•ˆì •ì„±
torch.backends.cudnn.deterministic = True        # ê²°ì •ì  ì•Œê³ ë¦¬ì¦˜

# 2. CUDA í™˜ê²½ ì„¤ì •
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
os.environ['CUDNN_CONV_WORKSPACE_LIMIT'] = '512'  # 512MB ì œí•œ
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512,expandable_segments:True'

# 3. ì •ë°€ë„ ìµœì í™”
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True

# 4. ê²°ì •ì  ì•Œê³ ë¦¬ì¦˜
torch.use_deterministic_algorithms(True, warn_only=True)

# 5. ì´ˆê¸° ë©”ëª¨ë¦¬ ì •ë¦¬
if torch.cuda.is_available():
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    
    print("=" * 60)
    print("ğŸ® GPU ì„¤ì • í™•ì¸")
    print("=" * 60)
    print(f"  GPU: {torch.cuda.get_device_name(0)}")
    print(f"  VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    print(f"  CUDA ë²„ì „: {torch.version.cuda}")
    print(f"  cuDNN í™œì„±í™”: {torch.backends.cudnn.enabled} âœ…")
    print(f"  Deterministic: {torch.backends.cudnn.deterministic}")
    print(f"  Benchmark: {torch.backends.cudnn.benchmark}")
    print("=" * 60)
else:
    raise RuntimeError("CUDA ì‚¬ìš© ë¶ˆê°€")

# ============================================================
# âœ… 8GB VRAM ìµœì í™” ë§¤ê°œë³€ìˆ˜
# ============================================================

INPUT_IMAGE = 'my/input/bag.jpg'
REMOVE_BACKGROUND = True

# í˜•ìƒ ìƒì„± (ë©”ëª¨ë¦¬ ì ˆì•½)
NUM_INFERENCE_STEPS = 4
OCTREE_RESOLUTION = 128              # 8GBì—ì„œ ì•ˆì „
GUIDANCE_SCALE = 5

# í…ìŠ¤ì²˜ ìƒì„± (ë©”ëª¨ë¦¬ ì ˆì•½)
DELIGHT_INFERENCE_STEPS = 5
MULTIVIEW_INFERENCE_STEPS = 5

# ì¹´ë©”ë¼ ë·° (ë©”ëª¨ë¦¬+ì†ë„ ì ˆì•½)
CAMERA_VIEWS = 'fast'                # 4ë·°

# ë Œë”ë§ (ë©”ëª¨ë¦¬ ì ˆì•½)
RENDER_SIZE = 1536                   # 2048 â†’ 1536
TEXTURE_SIZE = 1536                  # 2048 â†’ 1536

# ============================================================

# ë‚˜ë¨¸ì§€ ì½”ë“œëŠ” ë™ì¼...
```

---

### ì™„ì „í•œ multiview.py ì„¤ì •

```python
import torch
import os
import time
from datetime import datetime
from PIL import Image
from hy3dgen.texgen import Hunyuan3DPaintPipeline
from hy3dgen.shapegen import Hunyuan3DDiTFlowMatchingPipeline
from hy3dgen.rembg import BackgroundRemover

# ============================================================
# âœ… cuDNN í™œì„±í™” + 8GB VRAM ìµœì í™” ì„¤ì •
# ============================================================

# 1. cuDNN ì•ˆì „ í™œì„±í™”
torch.backends.cudnn.enabled = True              # âœ… Trueë¡œ ë³€ê²½!
torch.backends.cudnn.benchmark = False           # ë©”ëª¨ë¦¬ ì•ˆì •ì„±
torch.backends.cudnn.deterministic = True        # ê²°ì •ì  ì•Œê³ ë¦¬ì¦˜

# 2. CUDA í™˜ê²½ ì„¤ì •
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
os.environ['CUDNN_CONV_WORKSPACE_LIMIT'] = '512'  # 512MB ì œí•œ
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512,expandable_segments:True'

# 3. ì •ë°€ë„ ìµœì í™”
torch.backends.cuda.matmul.allow_tf32 = True
torch.backends.cudnn.allow_tf32 = True
torch.use_deterministic_algorithms(True, warn_only=True)

# 4. ì´ˆê¸°í™” ë° í™•ì¸
if torch.cuda.is_available():
    torch.cuda.init()
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
    
    print("=" * 60)
    print("ğŸ® GPU ì„¤ì • í™•ì¸ (cuDNN í™œì„±í™”)")
    print("=" * 60)
    print(f"  GPU: {torch.cuda.get_device_name(0)}")
    print(f"  VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    print(f"  CUDA ë²„ì „: {torch.version.cuda}")
    print(f"  cuDNN í™œì„±í™”: {torch.backends.cudnn.enabled} âœ…")
    print(f"  Deterministic: {torch.backends.cudnn.deterministic}")
    print(f"  Benchmark: {torch.backends.cudnn.benchmark}")
    print("=" * 60)
else:
    print("âš ï¸ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    exit(1)

# ============================================================
# ë‚˜ë¨¸ì§€ ì„¤ì •...
# ============================================================
```

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ: cuDNN False vs True (8GB VRAM)

### ì„¤ì •: OCTREE 128, 4ë·°, 1536 í•´ìƒë„

| í•­ëª© | cuDNN=False | cuDNN=True | ê°œì„  |
|------|-------------|------------|------|
| **Shape ìƒì„±** | 8ì´ˆ | **5ì´ˆ** | 37.5% ë¹ ë¦„ |
| **Delight** | 22ì´ˆ | **15ì´ˆ** | 31.8% ë¹ ë¦„ |
| **Multiview** | 280ì´ˆ | **190ì´ˆ** | 32.1% ë¹ ë¦„ |
| **UV ë˜í•‘** | 22ì´ˆ | 20ì´ˆ | 9% ë¹ ë¦„ |
| **ì¸í˜ì¸íŒ…** | 35ì´ˆ | 30ì´ˆ | 14.3% ë¹ ë¦„ |
| **ì´ ì‹œê°„** | 520ì´ˆ | **360ì´ˆ** | **30.8% ë¹ ë¦„** |
| **VRAM ì‚¬ìš©** | 7.5GB | **7.8GB** | +0.3GB |

---

## âš ï¸ ì£¼ì˜ì‚¬í•­ ë° ë¬¸ì œ í•´ê²°

### 1. OOM ì—ëŸ¬ ë°œìƒ ì‹œ

```python
# color.pyì— ì¶”ê°€

# âœ… ë” ì—„ê²©í•œ ë©”ëª¨ë¦¬ ì œí•œ
os.environ['CUDNN_CONV_WORKSPACE_LIMIT'] = '256'  # 512 â†’ 256
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:256'

# âœ… í•´ìƒë„ ë” ë‚®ì¶”ê¸°
OCTREE_RESOLUTION = 128
RENDER_SIZE = 1024  # 1536 â†’ 1024
TEXTURE_SIZE = 1024
CAMERA_VIEWS = 'minimal'  # fast â†’ minimal (3ë·°)
```

### 2. cuDNN ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ

```python
# ì—ëŸ¬ ë©”ì‹œì§€: "cuDNN error: CUDNN_STATUS_NOT_INITIALIZED"

# í•´ê²°ì±… 1: ë“œë¼ì´ë²„ ì—…ë°ì´íŠ¸
# NVIDIA ë“œë¼ì´ë²„ ìµœì‹  ë²„ì „ ì„¤ì¹˜

# í•´ê²°ì±… 2: PyTorch ì¬ì„¤ì¹˜
# pip uninstall torch torchvision
# pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118

# í•´ê²°ì±… 3: í™˜ê²½ ë³€ìˆ˜ ì¶”ê°€
os.environ['CUDA_MODULE_LOADING'] = 'LAZY'
```

### 3. ì†ë„ê°€ ëŠë¦° ê²½ìš°

```python
# benchmark=Trueë¡œ ì‹œë„ (ë©”ëª¨ë¦¬ ì¶©ë¶„í•  ë•Œë§Œ)
torch.backends.cudnn.benchmark = True  # ì´ˆê¸° ëŠë¦¼, ì´í›„ ë¹ ë¦„

# ë˜ëŠ” JIT ì»´íŒŒì¼
if hasattr(torch, 'compile'):
    model = torch.compile(model, mode='reduce-overhead')
```

### 4. ì¬í˜„ì„±ì´ í•„ìš”í•œ ê²½ìš°

```python
# ì™„ì „í•œ ì¬í˜„ì„±
torch.manual_seed(42)
torch.cuda.manual_seed(42)
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False
torch.use_deterministic_algorithms(True)

# ë‹¨, ì†ë„ê°€ ì•½ê°„ ëŠë ¤ì§ˆ ìˆ˜ ìˆìŒ
```

---

## ğŸ”§ ê³ ê¸‰ ìµœì í™”: cuDNN + ì¶”ê°€ ê¸°ë²•

### 1. cuDNN + VAE Tiling

```python
# hy3dgen/texgen/utils/dehighlight_utils.py

class Light_Shadow_Remover():
    def __init__(self, config):
        # ... ê¸°ì¡´ ì½”ë“œ ...
        
        # âœ… cuDNN + VAE ìµœì í™” ì¡°í•©
        if hasattr(self.pipeline, 'vae'):
            self.pipeline.vae.enable_tiling()
            self.pipeline.vae.enable_slicing()
        
        self.pipeline.enable_attention_slicing(slice_size='auto')
        
        self.pipeline = pipeline.to(self.device, torch.float16)
```

**íš¨ê³¼**: cuDNN í™œì„±í™” + VAE ìµœì í™” = **ìµœëŒ€ ì„±ëŠ¥**

### 2. cuDNN + Attention Slicing

```python
# hy3dgen/texgen/utils/multiview_utils.py

class Multiview_Diffusion_Net():
    def __init__(self, config) -> None:
        # ... ê¸°ì¡´ ì½”ë“œ ...
        
        # âœ… cuDNN + Attention ìµœì í™”
        self.pipeline.enable_attention_slicing(slice_size='auto')
        
        if hasattr(pipeline, 'vae'):
            pipeline.vae.enable_tiling()
            pipeline.vae.enable_slicing()
        
        self.pipeline = pipeline.to(self.device)
```

### 3. cuDNN + ìˆœì°¨ ë¡œë“œ (ìµœì¢… ì¡°í•©)

```python
# hy3dgen/texgen/pipelines.py

@torch.no_grad()
def __call__(self, mesh, image):
    # âœ… cuDNN + ìˆœì°¨ ë¡œë“œ + VAE + Attention
    
    # Delight ë‹¨ê³„
    self.load_delight_model()
    with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16):
        images_prompt = [self.models['delight_model'](img) for img in images_prompt]
    self.unload_delight_model()
    torch.cuda.empty_cache()  # cuDNN ìºì‹œë„ ì •ë¦¬
    
    # ... ë Œë”ë§ ...
    
    # Multiview ë‹¨ê³„
    self.load_multiview_model()
    with torch.cuda.amp.autocast(enabled=True, dtype=torch.float16):
        multiviews = self.models['multiview_model'](...)
    self.unload_multiview_model()
    torch.cuda.empty_cache()
    
    # ...
```

**ìµœì¢… íš¨ê³¼**:
- ë©”ëª¨ë¦¬: 8GB ì´ë‚´ âœ…
- ì†ë„: cuDNN False ëŒ€ë¹„ **30-40% ë¹ ë¦„** âš¡
- ì•ˆì •ì„±: ë§¤ìš° ë†’ìŒ âœ…

---

## ğŸ“‹ cuDNN í™œì„±í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

ì ìš© ì „ í™•ì¸:

- [ ] PyTorch 1.12+ ì„¤ì¹˜ í™•ì¸
- [ ] CUDA 11.7+ ì„¤ì¹˜ í™•ì¸
- [ ] NVIDIA ë“œë¼ì´ë²„ ìµœì‹  ë²„ì „
- [ ] ë‹¤ë¥¸ GPU í”„ë¡œê·¸ë¨ ì¢…ë£Œ
- [ ] ì‹œìŠ¤í…œ ì¬ë¶€íŒ… (ë©”ëª¨ë¦¬ ì´ˆê¸°í™”)

ì ìš© ë‹¨ê³„:

1. [ ] `color.py` ìƒë‹¨ì— cuDNN ì„¤ì • ì¶”ê°€
2. [ ] `CUDNN_CONV_WORKSPACE_LIMIT` í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
3. [ ] `deterministic=True` ì„¤ì •
4. [ ] 8GB ìµœì í™” ë§¤ê°œë³€ìˆ˜ ì ìš©
5. [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì‘ì€ ì´ë¯¸ì§€ë¡œ)
6. [ ] ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ (`nvidia-smi -l 1`)
7. [ ] OOM ë°œìƒ ì‹œ ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì œí•œ ê°ì†Œ

---

## ğŸ¯ ìµœì¢… ê¶Œì¥ ì„¤ì • (8GB VRAM + cuDNN)

### í”„ë¡œí† íƒ€ì… (ë¹ ë¦„)
```python
torch.backends.cudnn.enabled = True
torch.backends.cudnn.deterministic = True
os.environ['CUDNN_CONV_WORKSPACE_LIMIT'] = '512'

NUM_INFERENCE_STEPS = 3
OCTREE_RESOLUTION = 128
CAMERA_VIEWS = 'minimal'
RENDER_SIZE = 1024
TEXTURE_SIZE = 1024
```
â±ï¸ **ì‹œê°„**: ~280ì´ˆ (cuDNN False ëŒ€ë¹„ -100ì´ˆ)
ğŸ’¾ **VRAM**: ~6.8 GB

### ê· í˜• (ê¶Œì¥)
```python
torch.backends.cudnn.enabled = True
torch.backends.cudnn.deterministic = True
os.environ['CUDNN_CONV_WORKSPACE_LIMIT'] = '512'

NUM_INFERENCE_STEPS = 4
OCTREE_RESOLUTION = 128
CAMERA_VIEWS = 'fast'
RENDER_SIZE = 1536
TEXTURE_SIZE = 1536
```
â±ï¸ **ì‹œê°„**: ~360ì´ˆ (cuDNN False ëŒ€ë¹„ -160ì´ˆ)
ğŸ’¾ **VRAM**: ~7.6 GB

### ê³ í’ˆì§ˆ (í•œê³„)
```python
torch.backends.cudnn.enabled = True
torch.backends.cudnn.deterministic = True
os.environ['CUDNN_CONV_WORKSPACE_LIMIT'] = '384'  # ë” ì œí•œ

NUM_INFERENCE_STEPS = 5
OCTREE_RESOLUTION = 128  # 192ëŠ” ìœ„í—˜
CAMERA_VIEWS = 'fast'
RENDER_SIZE = 1536
TEXTURE_SIZE = 2048  # í…ìŠ¤ì²˜ë§Œ ë†’ì„
```
â±ï¸ **ì‹œê°„**: ~420ì´ˆ
ğŸ’¾ **VRAM**: ~7.9 GB (ì•„ìŠ¬ì•„ìŠ¬)

---

## ğŸ’¡ FAQ

### Q1: cuDNN Trueë¡œ í•˜ë©´ ì™œ ë¹ ë¥¸ê°€ìš”?
**A**: cuDNNì€ NVIDIAê°€ ë§Œë“  GPU ê°€ì† ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ì»¨ë³¼ë£¨ì…˜ ì—°ì‚°ì„ ìµœì í™”í•©ë‹ˆë‹¤. íŠ¹íˆ Diffusion ëª¨ë¸ì˜ U-Netì—ì„œ í° íš¨ê³¼ë¥¼ ë´…ë‹ˆë‹¤.

### Q2: deterministic=TrueëŠ” ì†ë„ì— ì˜í–¥ì´ ìˆë‚˜ìš”?
**A**: ì•½ê°„ ëŠë ¤ì§€ì§€ë§Œ (5-10%), ë©”ëª¨ë¦¬ ì•ˆì •ì„±ì´ í¬ê²Œ í–¥ìƒë©ë‹ˆë‹¤. 8GBì—ì„œëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.

### Q3: benchmark=False vs True ì°¨ì´ëŠ”?
**A**: 
- `False`: ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì•Œê³ ë¦¬ì¦˜ ì‚¬ìš© (8GB ê¶Œì¥)
- `True`: ê°€ì¥ ë¹ ë¥¸ ì•Œê³ ë¦¬ì¦˜ ì„ íƒ (ë©”ëª¨ë¦¬ ë” ì‚¬ìš©, 12GB+)

### Q4: OOMì´ ì—¬ì „íˆ ë°œìƒí•˜ë©´?
**A**: 
1. `CUDNN_CONV_WORKSPACE_LIMIT`ì„ 256ìœ¼ë¡œ ê°ì†Œ
2. `OCTREE_RESOLUTION`ì„ 128ë¡œ ìœ ì§€
3. `RENDER_SIZE`ë¥¼ 1024ë¡œ ê°ì†Œ
4. `CAMERA_VIEWS`ë¥¼ 'minimal'ë¡œ ë³€ê²½

### Q5: cuDNN True + CPU Offload ì¡°í•©ì€?
**A**: ê°€ëŠ¥í•˜ì§€ë§Œ ê¶Œì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. CPU Offloadì˜ ì´ì ì´ cuDNNìœ¼ë¡œ ìƒì‡„ë©ë‹ˆë‹¤.

---

## ğŸ¯ ê²°ë¡ 

**8GB VRAMì—ì„œ cuDNN í™œì„±í™” ê°€ëŠ¥!**

**í•µì‹¬ ì„¤ì •**:
```python
torch.backends.cudnn.enabled = True              # âœ… í™œì„±í™”
torch.backends.cudnn.deterministic = True        # âœ… í•„ìˆ˜
torch.backends.cudnn.benchmark = False           # âœ… í•„ìˆ˜
os.environ['CUDNN_CONV_WORKSPACE_LIMIT'] = '512' # âœ… ì œí•œ
```

**ì„±ëŠ¥ ê°œì„ **:
- ì†ë„: **30-40% í–¥ìƒ** âš¡
- ë©”ëª¨ë¦¬: +0.3GB (ì¶©ë¶„íˆ ê´€ë¦¬ ê°€ëŠ¥)
- ì•ˆì •ì„±: ë†’ìŒ (deterministic ë•ë¶„)

**ì˜ˆìƒ ê²°ê³¼**:
- cuDNN False: 520ì´ˆ, 7.5GB
- cuDNN True: **360ì´ˆ, 7.8GB** âœ…
- **ìˆœìˆ˜ ì‹œê°„ ì ˆì•½: 160ì´ˆ (30.8%)** ğŸ‰

---

**ì‘ì„±ì¼**: 2025-11-02
**ë²„ì „**: cuDNN 8GB í™œì„±í™” ê°€ì´ë“œ v1.0
