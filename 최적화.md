# TRELLIS 최적화 분석: microsoft/TRELLIS → IgorAherne/trellis-stable-projectorz

## 목차
1. [개요](#개요)
2. [메모리 최적화](#메모리-최적화)
3. [정밀도 최적화](#정밀도-최적화)
4. [동적 GPU 메모리 관리](#동적-gpu-메모리-관리)
5. [추론 최적화](#추론-최적화)
6. [파이프라인 최적화](#파이프라인-최적화)
7. [구조적 변경사항](#구조적-변경사항)
8. [성능 비교](#성능-비교)

---

## 개요

IgorAherne의 `trellis-stable-projectorz`는 Microsoft의 원본 TRELLIS를 8GB VRAM GPU에서 실행 가능하도록 최적화한 포크입니다. 주요 최적화 목표는:

- **VRAM 사용량 절반 감소**: 16GB → 8GB
- **상업적 사용 가능**: 라이센스 문제가 있는 종속성 제거
- **Windows 지원**: Windows 환경 원클릭 설치 제공
- **API 지원**: FastAPI를 통한 외부 통합

---

## 메모리 최적화

### 1. Float16 정밀도 지원

#### 원본 (Microsoft TRELLIS)
```python
# trellis/models/structured_latent_vae/base.py
self.dtype = torch.float32  # 항상 float32 사용
```

#### 최적화 버전 (IgorAherne)
```python
# trellis/models/structured_latent_vae/base.py (line 59)
self.dtype = torch.float16 if use_fp16 else torch.float32

# gradio_main.py (line 427-433)
def initialize_pipeline(precision="full"):
    global pipeline
    pipeline = TrellisImageTo3DPipeline.from_pretrained("jetx/TRELLIS-image-large")
    if precision == "half" or precision=="float16":
        pipeline.to(torch.float16)  # 메모리 사용량 절반으로 감소
        if "image_cond_model" in pipeline.models:
            pipeline.models['image_cond_model'].half()
```

**효과**: 모델 가중치 크기 50% 감소 (예: 1.2GB → 600MB)

### 2. Int32 인덱싱 사용

#### 원본
```python
# 대부분의 인덱싱에 int64 사용 (8바이트)
coords = torch.arange(res, dtype=torch.int64)
```

#### 최적화 버전
```python
# trellis/utils/postprocessing_utils.py (line 314)
faces = torch.tensor(faces.astype(np.int32)).cuda()

# trellis/representations/octree/octree_dfs.py (line 70)
self.structure = torch.tensor([[8, 1, 0]], dtype=torch.int32, device=self.device)

# trellis/modules/sparse/basic.py (line 286)
coords = coords.to(dtype=torch.int32, device=device)
```

**효과**: 인덱스 텐서 메모리 사용량 50% 감소

### 3. FlexiCubes 메모리 최적화

#### README.md에서 언급:
```markdown
For now my fork uses flexicubes fork https://github.com/IgorAherne/flexicubes-stable-projectorz
I've changed it to use `int32` instead of `int64`, reducing memory by half during SLAT decoding stage.
```

**구현 위치**:
```python
# trellis/representations/mesh/utils_cube.py (line 35, 55)
# dtype so that it works with half precision of the pipeline:
dense_attrs = torch.zeros([res] * 3 + [F], device=feats.device, dtype=feats.dtype)
```

**효과**: SLAT 디코딩 단계에서 메모리 사용량 절반으로 감소

---

## 정밀도 최적화

### 1. 동적 데이터 타입 감지

#### 구현
```python
# trellis/pipelines/trellis_image_to_3d.py (line 144)
desired_dtype = self.models['image_cond_model'].patch_embed.proj.weight.dtype

# trellis/pipelines/trellis_image_to_3d.py (line 190)
desired_dtype = next(flow_model.parameters()).dtype

# trellis/modules/norm.py (line 7)
needed_dtype = self.weight.dtype if self.weight is not None else x.dtype
```

**목적**: 파이프라인 전체에서 일관된 정밀도 유지 (float16/float32)

### 2. 정밀도 변환 주의사항

```python
# trellis/utils/postprocessing_utils.py (line 233)
vertices = vertices.astype(np.float32)  # pipeline can return half-precision, 
                                         # so cast to float32 else pv.PolyData() or 
                                         # torch.rasterize_triangle_faces will complain

# trellis/utils/postprocessing_utils.py (line 316)
observations = [torch.tensor(obs / 255.0, dtype=torch.float16).cuda() for obs in observations]
# float16 instead of float32, to fit into low VRAM gpus
```

**전략**: 
- 계산이 필요한 부분은 float16 유지
- 외부 라이브러리 호출 시 float32로 변환

---

## 동적 GPU 메모리 관리

### 1. CPU 오프로딩 전략

#### Background 제거 최적화
```python
# trellis/pipelines/trellis_image_to_3d.py (line 108)
if getattr(self, 'rembg_session', None) is None:
    self.rembg_session = rembg.new_session('u2net', providers=["CPUExecutionProvider"])
    # drastically reduces VRAM by running on CPU
output = rembg.remove(input, session=self.rembg_session)
```

**효과**: Background 제거를 CPU에서 실행하여 GPU 메모리 절약

### 2. 이미지 전처리 최적화

```python
# trellis/pipelines/trellis_image_to_3d.py (line 95-99)
# 1) Force max dimension 1024 BEFORE background removal
if max(input.size) > 1024:
    scale = 1024 / max(input.size)
    new_w = int(input.width * scale)
    new_h = int(input.height * scale)
    input = input.resize((new_w, new_h), Image.Resampling.LANCZOS)
```

**효과**: 메모리 사용량 감소 및 처리 속度 향상

### 3. 메모리 제한 테스트 모드

```python
# api_spz/main_api.py (line 8-10)
# only used for debugging, to emulate low-vram graphics cards:
# torch.cuda.set_per_process_memory_fraction(0.43)  # Limit to 43% of available VRAM
# os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128,garbage_collection_threshold:0.8'
```

**목적**: 저사양 GPU 환경 시뮬레이션 및 최적화 검증

---

## 추론 최적화

### 1. Attention Backend 선택

#### 원본
```python
# 기본적으로 flash-attn 사용
os.environ['ATTN_BACKEND'] = 'flash-attn'
```

#### 최적화 버전
```python
# gradio_main.py (line 6-10)
try: 
   import xformers
   os.environ['ATTN_BACKEND'] = 'xformers'
except ImportError:
   os.environ['ATTN_BACKEND'] = 'flash-attn'

# api_spz/main_api.py (line 94-98)
try:
   import xformers
   os.environ['ATTN_BACKEND'] = 'xformers'
except ImportError:
   os.environ['ATTN_BACKEND'] = 'flash-attn'
```

**전략**: 
- xformers가 설치된 경우 우선 사용 (더 나은 Windows 호환성)
- 없으면 flash-attn으로 폴백

### 2. SPCONV 알고리즘 설정

```python
# gradio_main.py (line 11)
os.environ['SPCONV_ALGO'] = 'native'

# trellis/modules/sparse/conv/__init__.py
SPCONV_ALGO = 'auto'  # 원본: 'auto' (벤치마킹 수행)
                      # 최적화: 'native' (단일 실행 시 추천)
```

**효과**: 초기 벤치마킹 오버헤드 제거

---

## 파이프라인 최적화

### 1. Texture Baking 최적화

```python
# trellis/utils/postprocessing_utils.py
def bake_texture(
    ...
    cancel_event=None,  # 새로 추가된 취소 메커니즘
):
    # Fast mode optimization
    if mode == 'fast':
        for observation, view, projection in tqdm(...):
            if cancel_event and cancel_event.is_set(): 
                raise CancelledException(f"Cancelled the texture baking (fast).")
            ...
    
    # Optimization mode with cancellation support
    elif mode == 'opt':
        for step in range(total_steps):
            if cancel_event and cancel_event.is_set(): 
                raise CancelledException(f"Cancelled texture optimization at step {step}/{total_steps}.")
            ...
```

**효과**: 
- 사용자가 긴 프로세스 취소 가능
- 리소스 낭비 방지

### 2. Mesh 후처리 최적화

```python
# trellis/utils/postprocessing_utils.py (line 230-236)
def postprocess_mesh(...):
    if verbose:
        tqdm.write(f'Before postprocess: {vertices.shape[0]} vertices, {faces.shape[0]} faces')

    vertices = vertices.astype(np.float32)  # pipeline can return half-precision
    
    # Simplify
    if simplify and simplify_ratio > 0:
        ...
```

**주요 개선사항**:
- Half precision 입력 처리
- 명시적인 타입 변환으로 호환성 보장

---

## 구조적 변경사항

### 1. API 서버 추가

```python
# api_spz/main_api.py
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware

@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("Trellis API Server is starting up")
    yield
    logger.info("Trellis API Server is shutting down")

app = FastAPI(title="Trellis API", lifespan=lifespan)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

**기능**:
- RESTful API 엔드포인트
- C#, Unity 등 외부 애플리케이션 통합
- CORS 지원

### 2. 상태 관리 시스템

```python
# api_spz/core/state_manage.py
class TrellisState:
    def __init__(self):
        self.temp_dir = Path("temp")
        self.temp_dir.mkdir(exist_ok=True)

    def initialize_pipeline(self, precision="full"):
        global pipeline
        pipeline = TrellisImageTo3DPipeline.from_pretrained("jetx/TRELLIS-image-large")
        if precision == "half" or precision=="float16":
            pipeline.to(torch.float16)
            if "image_cond_model" in pipeline.models:
                pipeline.models['image_cond_model'].half()
        state.pipeline = pipeline
```

**장점**:
- 전역 상태 관리
- 파이프라인 재사용
- 메모리 효율성

### 3. 로깅 시스템 개선

```python
# api_spz/main_api.py (line 25-33)
class TritonFilter(logging.Filter):
    def filter(self, record):
        # Filter out triton-related messages
        return 'triton' not in record.getMessage().lower()

logger = logging.getLogger("trellis")
logger.setLevel(logging.INFO)
logger.propagate = False
handler = logging.StreamHandler()
handler.addFilter(TritonFilter())
```

**효과**: 불필요한 로그 필터링, 가독성 향상

---

## 성능 비교

### 메모리 사용량 비교

| 구성요소 | Microsoft TRELLIS | IgorAherne 최적화 | 감소율 |
|---------|------------------|------------------|-------|
| 모델 가중치 (float) | ~1.2GB (fp32) | ~600MB (fp16) | 50% |
| 인덱스 텐서 (int) | int64 | int32 | 50% |
| SLAT 디코딩 | int64 | int32 | 50% |
| Background 제거 | GPU | CPU | GPU 메모리 절약 |
| 총 VRAM 요구사항 | ~16GB | ~8GB | 50% |

### 정밀도 영향

```python
# 원본: 전체 float32 (약 7자리 정밀도)
# 최적화: float16 (약 3-4자리 정밀도)
```

**품질 영향**:
- 시각적 품질: 거의 차이 없음
- 수치 안정성: 대부분의 경우 충분
- 특수 케이스: 극단적인 스케일에서 문제 발생 가능

### 속도 개선

1. **추론 속도**: float16 연산이 일반적으로 더 빠름 (GPU 지원 시)
2. **메모리 전송**: 데이터 전송량 50% 감소
3. **초기화 시간**: 벤치마킹 제거로 개선

---

## 핵심 최적화 기법 요약

### 1. 정밀도 하향 조정
- **float32 → float16**: 메모리 50% 감소, 속도 향상
- **int64 → int32**: 인덱스 메모리 50% 감소
- **동적 타입 감지**: 파이프라인 전체 일관성 유지

### 2. 선택적 CPU 오프로딩
- **Background 제거**: CPU에서 실행
- **이미지 전처리**: 크기 제한으로 메모리 절약

### 3. 알고리즘 최적화
- **Attention backend**: 환경에 맞는 최적 선택
- **SPCONV**: 벤치마킹 제거 옵션

### 4. 아키텍처 개선
- **API 서버**: 외부 통합 지원
- **취소 메커니즘**: 긴 작업 중단 가능
- **상태 관리**: 효율적인 리소스 사용

---

## 구현 예시: 직접 적용하기

### 기존 프로젝트에 최적화 적용

```python
import torch
from trellis.pipelines import TrellisImageTo3DPipeline

# 1. 파이프라인 로드
pipeline = TrellisImageTo3DPipeline.from_pretrained("jetx/TRELLIS-image-large")

# 2. 메모리 최적화 적용
pipeline.to(torch.float16)  # float16으로 변환
if "image_cond_model" in pipeline.models:
    pipeline.models['image_cond_model'].half()

# 3. CPU 오프로딩 설정
import rembg
rembg_session = rembg.new_session('u2net', providers=["CPUExecutionProvider"])

# 4. 환경 변수 설정
import os
os.environ['SPCONV_ALGO'] = 'native'
try:
    import xformers
    os.environ['ATTN_BACKEND'] = 'xformers'
except ImportError:
    os.environ['ATTN_BACKEND'] = 'flash-attn'

# 5. 추론 실행
outputs = pipeline.run(image, seed=1)
```

### 메모리 사용량 모니터링

```python
import torch

def print_memory_usage():
    if torch.cuda.is_available():
        allocated = torch.cuda.memory_allocated() / 1024**3
        reserved = torch.cuda.memory_reserved() / 1024**3
        print(f"Allocated: {allocated:.2f}GB, Reserved: {reserved:.2f}GB")

# 추론 전후 메모리 확인
print_memory_usage()
outputs = pipeline.run(image)
print_memory_usage()
```

---

## 결론

IgorAherne의 `trellis-stable-projectorz`는 다음과 같은 체계적인 최적화를 통해 Microsoft TRELLIS를 8GB VRAM GPU에서 실행 가능하게 만들었습니다:

1. **메모리 최적화**: float16/int32 사용으로 50% 메모리 감소
2. **동적 관리**: CPU 오프로딩 및 동적 타입 감지
3. **아키텍처 개선**: API 서버, 취소 메커니즘, 상태 관리
4. **환경 최적화**: Backend 선택 및 알고리즘 튜닝

이러한 최적화는 **품질 손실을 최소화하면서 접근성을 크게 향상**시켰으며, 저사양 GPU 사용자들도 고품질 3D 생성 기술을 활용할 수 있게 했습니다.

---

## 참조

- [Microsoft TRELLIS](https://github.com/microsoft/TRELLIS)
- [IgorAherne trellis-stable-projectorz](https://github.com/IgorAherne/trellis-stable-projectorz)
- [FlexiCubes 최적화 포크](https://github.com/IgorAherne/flexicubes-stable-projectorz)
- [StableProjectorz](https://stableprojectorz.com/)

---

*문서 작성일: 2025년 11월 2일*
