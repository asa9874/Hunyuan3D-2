# TRELLIS 최적화 기법의 Hunyuan3D-2 적용 가능성 분석

## 📋 개요

TRELLIS 프로젝트에서 사용된 8GB VRAM 최적화 기법들을 Hunyuan3D-2에 적용할 수 있는지 분석한 문서입니다.

**분석 대상**: 
- Microsoft TRELLIS → IgorAherne/trellis-stable-projectorz 최적화
- Hunyuan3D-2 현재 구현

**목표**:
- 적용 가능한 최적화 식별
- 구체적인 적용 방법 제시
- 예상 효과 및 주의사항 정리

---

## 🎯 최적화 기법별 적용 가능성

### 1. Float16 정밀도 지원 ⭐⭐⭐⭐⭐

#### TRELLIS 구현
```python
# 동적 정밀도 전환
pipeline.to(torch.float16)
if "image_cond_model" in pipeline.models:
    pipeline.models['image_cond_model'].half()
```

#### Hunyuan3D-2 현재 상태

**✅ 이미 부분적으로 적용됨**

```python
# hy3dgen/shapegen/pipelines.py (line 207)
def from_pretrained(cls, model_path, device='cuda', dtype=torch.float16, ...):
    # 기본값이 float16

# hy3dgen/texgen/utils/dehighlight_utils.py (line 31)
pipeline = StableDiffusionInstructPix2PixPipeline.from_pretrained(
    config.light_remover_ckpt_path,
    torch_dtype=torch.float16,  # ✅ 이미 float16 사용
    safety_checker=None,
)

# hy3dgen/texgen/utils/multiview_utils.py (line 37)
pipeline = DiffusionPipeline.from_pretrained(
    multiview_ckpt_path,
    custom_pipeline=custom_pipeline_path, 
    torch_dtype=torch.float16  # ✅ 이미 float16 사용
)
```

#### 추가 적용 가능성

**거의 없음** - 이미 텍스처 생성 파이프라인에서 float16을 기본으로 사용 중

**예상 효과**: 현재 상태 유지 (이미 최적화됨)

---

### 2. CPU 오프로딩 (Background 제거) ⭐⭐⭐⭐⭐

#### TRELLIS 구현
```python
# CPU에서 background 제거 실행
self.rembg_session = rembg.new_session('u2net', providers=["CPUExecutionProvider"])
output = rembg.remove(input, session=self.rembg_session)
```

#### Hunyuan3D-2 현재 상태

**❌ GPU에서 실행 중**

```python
# hy3dgen/rembg.py
class BackgroundRemover():
    def __init__(self):
        self.session = new_session()  # ❌ 기본값 = GPU 사용

    def __call__(self, image: Image.Image):
        output = remove(image, session=self.session, bgcolor=[255, 255, 255, 0])
        return output
```

#### ✅ 적용 방법

```python
# hy3dgen/rembg.py 수정

class BackgroundRemover():
    def __init__(self, use_cpu=True):  # ✅ CPU 사용 옵션 추가
        """
        Args:
            use_cpu (bool): True면 CPU에서 실행 (GPU 메모리 절약)
                           False면 GPU에서 실행 (빠르지만 메모리 사용)
        """
        if use_cpu:
            # ✅ CPU에서 실행 (VRAM 절약)
            self.session = new_session('u2net', providers=["CPUExecutionProvider"])
            print("✅ Background 제거: CPU 모드 (VRAM 절약)")
        else:
            # GPU에서 실행 (빠름)
            self.session = new_session('u2net')
            print("⚡ Background 제거: GPU 모드 (빠름)")

    def __call__(self, image: Image.Image):
        output = remove(image, session=self.session, bgcolor=[255, 255, 255, 0])
        return output
```

```python
# color.py에서 사용
from hy3dgen.rembg import BackgroundRemover

# ✅ 8GB VRAM이면 CPU 모드 권장
if REMOVE_BACKGROUND:
    rembg = BackgroundRemover(use_cpu=True)  # VRAM 절약
    image = rembg(image)
```

**예상 효과**:
- VRAM 절약: **~1-1.5 GB**
- 속도 영향: +2-3초 (하지만 OOM 방지)
- 적용 난이도: 매우 쉬움 ⭐

---

### 3. 이미지 크기 사전 제한 ⭐⭐⭐⭐

#### TRELLIS 구현
```python
# Background 제거 전에 크기 제한
if max(input.size) > 1024:
    scale = 1024 / max(input.size)
    new_w = int(input.width * scale)
    new_h = int(input.height * scale)
    input = input.resize((new_w, new_h), Image.Resampling.LANCZOS)
```

#### Hunyuan3D-2 현재 상태

**❌ 크기 제한 없음** - 원본 크기 그대로 처리

#### ✅ 적용 방법

```python
# color.py 또는 hy3dgen/rembg.py에 추가

def preprocess_image_size(image, max_size=1024):
    """
    이미지 크기를 제한하여 메모리 절약
    
    Args:
        image (PIL.Image): 입력 이미지
        max_size (int): 최대 크기 (기본: 1024)
    
    Returns:
        PIL.Image: 리사이즈된 이미지
    """
    if max(image.size) > max_size:
        scale = max_size / max(image.size)
        new_w = int(image.width * scale)
        new_h = int(image.height * scale)
        print(f"  이미지 리사이즈: {image.size} → ({new_w}, {new_h})")
        return image.resize((new_w, new_h), Image.Resampling.LANCZOS)
    return image
```

```python
# color.py에서 사용
image = Image.open(INPUT_IMAGE)
original_mode = image.mode
print(f"  - 원본 이미지 모드: {original_mode}")

# ✅ 크기 제한 (메모리 절약)
image = preprocess_image_size(image, max_size=1024)

# 배경 제거
if REMOVE_BACKGROUND:
    rembg = BackgroundRemover(use_cpu=True)
    image = rembg(image)
```

**예상 효과**:
- VRAM 절약: **~0.5-1 GB** (고해상도 이미지에서)
- 속도 향상: +1-2초 빨라짐
- 품질 영향: 1024px 이상에서는 거의 무시 가능
- 적용 난이도: 매우 쉬움 ⭐

---

### 4. Int32 인덱싱 사용 ⭐⭐

#### TRELLIS 구현
```python
# int64 → int32 변환
faces = torch.tensor(faces.astype(np.int32)).cuda()
coords = coords.to(dtype=torch.int32, device=device)
```

#### Hunyuan3D-2 현재 상태

**일부 int32 사용 중**

```python
# hy3dgen/shapegen/models/autoencoders/volume_decoders.py (line 118-119)
mask = (~same_sign).to(torch.int32)  # ✅ 이미 int32 사용
return mask * valid_mask.to(torch.int32)
```

**하지만 scheduler에서 int64 사용**

```python
# hy3dgen/shapegen/schedulers.py (line 343, 401)
euler_timesteps = (np.arange(1, pcm_timesteps) * step_ratio).round().astype(np.int64)  # ❌
inference_indices = np.floor(inference_indices).astype(np.int64)  # ❌
```

#### ⚠️ 적용 가능성: 제한적

**주의사항**:
- Scheduler의 timestep 계산은 int64가 안전
- 잘못 변경 시 수치 오버플로우 가능
- 메모리 절약 효과가 크지 않음 (~100MB)

**권장**: 현재 상태 유지 (리스크 > 이득)

---

### 5. VAE Tiling & Slicing ⭐⭐⭐⭐⭐

#### TRELLIS 구현
```python
if hasattr(pipeline, 'vae'):
    pipeline.vae.enable_tiling()
    pipeline.vae.enable_slicing()
```

#### Hunyuan3D-2 현재 상태

**❌ 미적용** - VAE 최적화 기능 없음

#### ✅ 적용 방법

```python
# hy3dgen/texgen/utils/dehighlight_utils.py 수정

class Light_Shadow_Remover():
    def __init__(self, config):
        self.device = config.device
        self.cfg_image = 1.5
        self.cfg_text = 1.0
        self.num_inference_steps = getattr(config, 'delight_inference_steps', 6)

        pipeline = StableDiffusionInstructPix2PixPipeline.from_pretrained(
            config.light_remover_ckpt_path,
            torch_dtype=torch.float16,
            safety_checker=None,
        )
        pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(
            pipeline.scheduler.config)

        # ✅ VAE 메모리 최적화 추가
        if hasattr(pipeline, 'vae'):
            try:
                pipeline.vae.enable_tiling()
                print("    ✓ VAE Tiling 활성화")
            except:
                pass
            
            try:
                pipeline.vae.enable_slicing()
                print("    ✓ VAE Slicing 활성화")
            except:
                pass

        self.pipeline = pipeline.to(self.device, torch.float16)
```

```python
# hy3dgen/texgen/utils/multiview_utils.py 수정

class Multiview_Diffusion_Net():
    def __init__(self, config) -> None:
        self.device = config.device
        self.view_size = 512
        self.num_inference_steps = getattr(config, 'multiview_inference_steps', 6)
        multiview_ckpt_path = config.multiview_ckpt_path

        current_file_path = os.path.abspath(__file__)
        custom_pipeline_path = os.path.join(os.path.dirname(current_file_path), '..', 'hunyuanpaint')

        pipeline = DiffusionPipeline.from_pretrained(
            multiview_ckpt_path,
            custom_pipeline=custom_pipeline_path, 
            torch_dtype=torch.float16
        )

        if config.pipe_name in ['hunyuanpaint']:
            pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(
                pipeline.scheduler.config,
                timestep_spacing='trailing')
        elif config.pipe_name in ['hunyuanpaint-turbo']:
            pipeline.scheduler = LCMScheduler.from_config(
                pipeline.scheduler.config,
                timestep_spacing='trailing')
            pipeline.set_turbo(True)

        # ✅ VAE 메모리 최적화 추가
        if hasattr(pipeline, 'vae'):
            try:
                pipeline.vae.enable_tiling()
                print("    ✓ VAE Tiling 활성화")
            except:
                pass
            
            try:
                pipeline.vae.enable_slicing()
                print("    ✓ VAE Slicing 활성화")
            except:
                pass

        self.pipeline = pipeline.to(self.device)
```

**예상 효과**:
- VRAM 절약: **~1-2 GB**
- 속도 영향: 거의 없음 (±5초)
- 적용 난이도: 쉬움 ⭐⭐

---

### 6. Attention Slicing ⭐⭐⭐⭐⭐

#### TRELLIS 구현
```python
pipeline.enable_attention_slicing(slice_size='auto')
```

#### Hunyuan3D-2 현재 상태

**❌ 미적용**

#### ✅ 적용 방법

```python
# hy3dgen/texgen/utils/dehighlight_utils.py 수정

class Light_Shadow_Remover():
    def __init__(self, config):
        # ... 기존 코드 ...
        
        # ✅ Attention Slicing 추가
        try:
            self.pipeline.enable_attention_slicing(slice_size='auto')
            print("    ✓ Attention Slicing 활성화 (메모리 절약)")
        except Exception as e:
            print(f"    ⚠ Attention Slicing 실패: {e}")

        self.pipeline = pipeline.to(self.device, torch.float16)
```

```python
# hy3dgen/texgen/utils/multiview_utils.py 수정

class Multiview_Diffusion_Net():
    def __init__(self, config) -> None:
        # ... 기존 코드 ...
        
        # ✅ Attention Slicing 추가
        try:
            self.pipeline.enable_attention_slicing(slice_size='auto')
            print("    ✓ Attention Slicing 활성화 (메모리 절약)")
        except Exception as e:
            print(f"    ⚠ Attention Slicing 실패: {e}")

        self.pipeline = pipeline.to(self.device)
```

**예상 효과**:
- VRAM 절약: **~2-3 GB** (가장 효과적!)
- 속도 영향: +10-15초 (느려지지만 메모리 안전)
- 적용 난이도: 쉬움 ⭐⭐

---

### 7. xFormers 우선 사용 ⭐⭐⭐

#### TRELLIS 구현
```python
try: 
   import xformers
   os.environ['ATTN_BACKEND'] = 'xformers'
except ImportError:
   os.environ['ATTN_BACKEND'] = 'flash-attn'
```

#### Hunyuan3D-2 현재 상태

**❌ xFormers 미사용**

#### ✅ 적용 방법

```python
# color.py 또는 multiview.py 최상단에 추가

import os

# ✅ xFormers 우선 사용 (메모리 효율적)
try:
    import xformers
    os.environ['ATTN_BACKEND'] = 'xformers'
    print("✅ xFormers 활성화 (메모리 효율적)")
except ImportError:
    print("⚠️ xFormers 미설치 - 설치 권장: pip install xformers")
```

**xFormers 설치**:
```bash
pip install xformers
```

**예상 효과**:
- VRAM 절약: **~1-1.5 GB**
- 속도: 약간 빠름 (5-10%)
- 적용 난이도: 쉬움 ⭐

---

### 8. 취소 메커니즘 ⭐⭐

#### TRELLIS 구현
```python
def bake_texture(..., cancel_event=None):
    for step in range(total_steps):
        if cancel_event and cancel_event.is_set(): 
            raise CancelledException(f"Cancelled at step {step}")
```

#### Hunyuan3D-2 현재 상태

**❌ 취소 기능 없음**

#### ⚠️ 적용 가능성: 제한적

**이유**:
- Hunyuan3D-2는 주로 배치/스크립트 실행
- TRELLIS는 Gradio UI 기반
- 취소 기능은 UI 환경에서 유용

**권장**: 현재는 불필요 (UI 개발 시 고려)

---

### 9. Torch Compile ⭐⭐⭐

#### TRELLIS에는 없지만 Hunyuan3D-2에 있음

```python
# hy3dgen/shapegen/pipelines.py (line 248)
def compile(self):
    self.vae = torch.compile(self.vae)
    self.model = torch.compile(self.model)
    self.conditioner = torch.compile(self.conditioner)
```

#### ✅ 이미 구현됨 (하지만 기본적으로 사용 안 함)

```python
# color.py에서 사용 예시
shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(...)

# ✅ 컴파일 활성화 (첫 실행 느림, 이후 빠름)
if hasattr(shape_pipeline, 'compile'):
    print("⏳ 모델 컴파일 중... (최초 1회만)")
    shape_pipeline.compile()
    print("✅ 컴파일 완료!")
```

**예상 효과**:
- 첫 실행: +30초 (컴파일)
- 이후 실행: -30-50초 (20-30% 빠름)

---

## 📊 통합 적용 시나리오

### 시나리오 A: **즉시 적용 가능 (최소 노력)** ⭐⭐⭐⭐⭐

#### 적용 내용
```python
# 1. Background 제거 CPU 오프로딩
# hy3dgen/rembg.py 수정 (위의 코드 참조)

# 2. 이미지 크기 제한
# color.py에 preprocess_image_size() 함수 추가

# 3. xFormers 활성화
# color.py 최상단에 추가
import os
try:
    import xformers
    os.environ['ATTN_BACKEND'] = 'xformers'
except ImportError:
    pass
```

**예상 효과**:
- VRAM 절약: **~2-3 GB**
- 시간 영향: +5초 (무시 가능)
- 안정성: 높음
- 적용 시간: 10분

---

### 시나리오 B: **VAE + Attention 최적화** ⭐⭐⭐⭐⭐

#### 적용 내용
```python
# 1. 시나리오 A 전체
# 2. VAE Tiling & Slicing
# 3. Attention Slicing

# hy3dgen/texgen/utils/dehighlight_utils.py 수정
if hasattr(pipeline, 'vae'):
    pipeline.vae.enable_tiling()
    pipeline.vae.enable_slicing()
pipeline.enable_attention_slicing(slice_size='auto')

# hy3dgen/texgen/utils/multiview_utils.py 수정
if hasattr(pipeline, 'vae'):
    pipeline.vae.enable_tiling()
    pipeline.vae.enable_slicing()
pipeline.enable_attention_slicing(slice_size='auto')
```

**예상 효과**:
- VRAM 절약: **~5-6 GB** (매우 효과적!)
- 시간 영향: +15-20초
- 안정성: 높음
- 적용 시간: 20분

---

### 시나리오 C: **최대 최적화 (모든 기법)** ⭐⭐⭐⭐⭐

#### 적용 내용
```python
# 1. 시나리오 B 전체
# 2. Torch Compile

# color.py에서
shape_pipeline.compile()
```

**예상 효과**:
- VRAM 절약: **~5-6 GB**
- 첫 실행: +30초 (컴파일)
- 이후 실행: -30초 (빠름)
- 총 시간 (2회차부터): **기존 대비 -15초**

---

## 📋 적용 우선순위 및 난이도

### 🥇 1순위: CPU 오프로딩 + 이미지 크기 제한

**이유**:
- 매우 쉬움 (10분)
- 즉시 효과 (2-3GB 절약)
- 부작용 없음

**적용 파일**:
- `hy3dgen/rembg.py` (3줄 수정)
- `color.py` (함수 1개 추가)

---

### 🥈 2순위: VAE + Attention 최적화

**이유**:
- 쉬움 (20분)
- 큰 효과 (5-6GB 절약)
- Diffusers 라이브러리 기본 기능

**적용 파일**:
- `hy3dgen/texgen/utils/dehighlight_utils.py` (5줄 추가)
- `hy3dgen/texgen/utils/multiview_utils.py` (5줄 추가)

---

### 🥉 3순위: xFormers + Torch Compile

**이유**:
- 중간 (30분)
- 속도 향상 + 메모리 절약
- 추가 라이브러리 설치 필요

**적용 파일**:
- `color.py` (최상단에 환경 변수)
- `color.py` (compile() 호출)

---

## ⚠️ 적용 불가능 또는 불필요한 기법

### ❌ Float16 정밀도
**이유**: 이미 기본값으로 사용 중

### ❌ Int32 인덱싱
**이유**: 리스크 > 이득 (~100MB 절약)

### ❌ 취소 메커니즘
**이유**: UI 없는 스크립트 환경

---

## 🎯 최종 권장 적용 코드

### 1. hy3dgen/rembg.py 수정

```python
from PIL import Image
from rembg import remove, new_session


class BackgroundRemover():
    def __init__(self, use_cpu=True):
        """
        Args:
            use_cpu (bool): True면 CPU에서 실행 (GPU 메모리 절약)
        """
        if use_cpu:
            self.session = new_session('u2net', providers=["CPUExecutionProvider"])
            print("✅ Background 제거: CPU 모드 (VRAM 절약)")
        else:
            self.session = new_session('u2net')
            print("⚡ Background 제거: GPU 모드 (빠름)")

    def __call__(self, image: Image.Image):
        output = remove(image, session=self.session, bgcolor=[255, 255, 255, 0])
        return output
```

---

### 2. hy3dgen/texgen/utils/dehighlight_utils.py 수정

```python
class Light_Shadow_Remover():
    def __init__(self, config):
        self.device = config.device
        self.cfg_image = 1.5
        self.cfg_text = 1.0
        self.num_inference_steps = getattr(config, 'delight_inference_steps', 6)

        pipeline = StableDiffusionInstructPix2PixPipeline.from_pretrained(
            config.light_remover_ckpt_path,
            torch_dtype=torch.float16,
            safety_checker=None,
        )
        pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(
            pipeline.scheduler.config)

        # ✅ VAE 최적화
        if hasattr(pipeline, 'vae'):
            try:
                pipeline.vae.enable_tiling()
                pipeline.vae.enable_slicing()
                print("    ✓ VAE Tiling/Slicing 활성화")
            except Exception as e:
                print(f"    ⚠ VAE 최적화 실패: {e}")

        # ✅ Attention Slicing
        try:
            pipeline.enable_attention_slicing(slice_size='auto')
            print("    ✓ Attention Slicing 활성화")
        except Exception as e:
            print(f"    ⚠ Attention Slicing 실패: {e}")

        self.pipeline = pipeline.to(self.device, torch.float16)
```

---

### 3. hy3dgen/texgen/utils/multiview_utils.py 수정

```python
class Multiview_Diffusion_Net():
    def __init__(self, config) -> None:
        self.device = config.device
        self.view_size = 512
        self.num_inference_steps = getattr(config, 'multiview_inference_steps', 6)
        multiview_ckpt_path = config.multiview_ckpt_path

        current_file_path = os.path.abspath(__file__)
        custom_pipeline_path = os.path.join(os.path.dirname(current_file_path), '..', 'hunyuanpaint')

        pipeline = DiffusionPipeline.from_pretrained(
            multiview_ckpt_path,
            custom_pipeline=custom_pipeline_path, 
            torch_dtype=torch.float16
        )

        if config.pipe_name in ['hunyuanpaint']:
            pipeline.scheduler = EulerAncestralDiscreteScheduler.from_config(
                pipeline.scheduler.config,
                timestep_spacing='trailing')
        elif config.pipe_name in ['hunyuanpaint-turbo']:
            pipeline.scheduler = LCMScheduler.from_config(
                pipeline.scheduler.config,
                timestep_spacing='trailing')
            pipeline.set_turbo(True)

        # ✅ VAE 최적화
        if hasattr(pipeline, 'vae'):
            try:
                pipeline.vae.enable_tiling()
                pipeline.vae.enable_slicing()
                print("    ✓ VAE Tiling/Slicing 활성화")
            except Exception as e:
                print(f"    ⚠ VAE 최적화 실패: {e}")

        # ✅ Attention Slicing
        try:
            pipeline.enable_attention_slicing(slice_size='auto')
            print("    ✓ Attention Slicing 활성화")
        except Exception as e:
            print(f"    ⚠ Attention Slicing 실패: {e}")

        self.pipeline = pipeline.to(self.device)
```

---

### 4. color.py 수정

```python
import torch
import os
import time
from datetime import datetime
from PIL import Image
from hy3dgen.texgen import Hunyuan3DPaintPipeline
from hy3dgen.shapegen import Hunyuan3DDiTFlowMatchingPipeline
from hy3dgen.rembg import BackgroundRemover

# ============================================================
# ✅ 외부 최적화 기법 적용
# ============================================================

# 1. xFormers 우선 사용
try:
    import xformers
    os.environ['ATTN_BACKEND'] = 'xformers'
    print("✅ xFormers 활성화 (메모리 효율적)")
except ImportError:
    print("⚠️ xFormers 미설치 - 설치 권장: pip install xformers")

# 2. 이미지 크기 제한 함수
def preprocess_image_size(image, max_size=1024):
    """이미지 크기를 제한하여 메모리 절약"""
    if max(image.size) > max_size:
        scale = max_size / max(image.size)
        new_w = int(image.width * scale)
        new_h = int(image.height * scale)
        print(f"  이미지 리사이즈: {image.size} → ({new_w}, {new_h})")
        return image.resize((new_w, new_h), Image.Resampling.LANCZOS)
    return image

# ============================================================
# 기존 설정...
# ============================================================

# 0. 이미지 로드 및 배경 제거
print("=" * 60)
print("입력 이미지를 처리합니다...")
start_time = time.time()

image = Image.open(INPUT_IMAGE)
original_mode = image.mode
print(f"  - 원본 이미지 모드: {original_mode}")

# ✅ 크기 제한 (메모리 절약)
image = preprocess_image_size(image, max_size=1024)

# ✅ CPU에서 배경 제거 (VRAM 절약)
if REMOVE_BACKGROUND and original_mode in ['RGB', 'L']:
    print("  - 배경 제거를 수행합니다...")
    if original_mode == 'L':
        image = image.convert('RGB')
    rembg = BackgroundRemover(use_cpu=True)  # ✅ CPU 모드
    image = rembg(image)
    print("  - 배경 제거 완료! (RGBA로 변환됨)")
elif REMOVE_BACKGROUND and original_mode == 'RGBA':
    print("  - 이미지에 이미 알파 채널이 있어 배경 제거를 건너뜁니다.")
else:
    image = image.convert("RGBA")

time_records['이미지 전처리'] = time.time() - start_time
print(f"완료! (소요 시간: {time_records['이미지 전처리']:.2f}초)")
print("=" * 60)

# ... 나머지 코드 동일 ...
```

---

## 📊 예상 성능 개선

### 시나리오별 비교

| 시나리오 | VRAM 절약 | 시간 영향 | 적용 난이도 | 추천도 |
|---------|----------|----------|------------|--------|
| **현재 (기준)** | - | - | - | - |
| **A: 즉시 적용** | -2-3 GB | +5초 | 쉬움 (10분) | ⭐⭐⭐⭐⭐ |
| **B: VAE+Attention** | -5-6 GB | +15초 | 쉬움 (20분) | ⭐⭐⭐⭐⭐ |
| **C: 최대 최적화** | -5-6 GB | -15초 (2회차~) | 중간 (30분) | ⭐⭐⭐⭐ |

### 구체적인 수치

```
현재 (기준)              : 7.5GB VRAM, 520초
──────────────────────────────────────────
시나리오 A (즉시 적용)    : 5.0GB VRAM, 525초
시나리오 B (VAE+Attn)    : 2.0GB VRAM, 535초  ✅ 가장 안전
시나리오 C (최대)         : 2.0GB VRAM, 490초  ⚡ 가장 빠름 (2회차~)
```

---

## 🎯 최종 결론

### ✅ 적용 가능하고 효과적인 기법

1. **CPU 오프로딩** (Background 제거) - 즉시 적용 ⭐⭐⭐⭐⭐
2. **이미지 크기 제한** - 즉시 적용 ⭐⭐⭐⭐⭐
3. **VAE Tiling/Slicing** - 20분 소요 ⭐⭐⭐⭐⭐
4. **Attention Slicing** - 20분 소요 ⭐⭐⭐⭐⭐
5. **xFormers 활성화** - 즉시 적용 ⭐⭐⭐⭐

### ❌ 적용 불필요한 기법

1. **Float16** - 이미 적용됨
2. **Int32** - 리스크 > 이득
3. **취소 메커니즘** - UI 환경 아님

### 🎁 보너스: 이미 있는 기능

1. **Torch Compile** - 활성화만 하면 됨

---

## 📝 체크리스트

### Phase 1: 즉시 적용 (10분)

- [ ] `hy3dgen/rembg.py` - CPU 오프로딩 추가
- [ ] `color.py` - 이미지 크기 제한 함수 추가
- [ ] `color.py` - xFormers 환경 변수 추가

**예상 효과**: -2-3 GB VRAM

---

### Phase 2: VAE + Attention (20분)

- [ ] `hy3dgen/texgen/utils/dehighlight_utils.py` - VAE/Attention 최적화
- [ ] `hy3dgen/texgen/utils/multiview_utils.py` - VAE/Attention 최적화

**예상 효과**: -5-6 GB VRAM (총 절약)

---

### Phase 3: 선택 사항 (10분)

- [ ] `color.py` - Torch Compile 활성화

**예상 효과**: 속도 20-30% 향상 (2회차부터)

---

**작성일**: 2025-11-02
**버전**: 외부 최적화 기법 적용 분석 v1.0
**대상**: Hunyuan3D-2 (8GB VRAM)
