# color.pyì—ì„œ ë†“ì¹˜ê³  ìˆëŠ” ìµœì í™” ìš”ì†Œ

## ğŸ“‹ ê°œìš”

í˜„ì¬ `color.py`ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ì½”ë“œë¥¼ ë¶„ì„í•œ ê²°ê³¼, **í”„ë¡œì íŠ¸ì— ì´ë¯¸ êµ¬í˜„ë˜ì–´ ìˆì§€ë§Œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ìµœì í™” ê¸°ëŠ¥ë“¤**ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. ì´ë“¤ì€ `gradio_app.py`ì™€ `multiview.py` ë“± ë‹¤ë¥¸ ìŠ¤í¬ë¦½íŠ¸ì—ì„œëŠ” ì‚¬ìš©ë˜ê³  ìˆìœ¼ë‚˜, `color.py`ì—ì„œëŠ” í™œì„±í™”ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.

---

## ğŸ”¥ ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ ê¸°ëŠ¥ë“¤

### 1. âš¡ **FlashVDM ìµœì í™”** (í˜•ìƒ ìƒì„± ì†ë„ í–¥ìƒ) â­â­â­â­â­

#### í˜„ì¬ ìƒíƒœ
```python
# color.py (line 75-80)
shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(
    'tencent/Hunyuan3D-2',
    subfolder='hunyuan3d-dit-v2-0-turbo',
    torch_dtype=torch.float16
)
shape_pipeline.to('cuda')
# âŒ FlashVDM ë¯¸ì‚¬ìš©
```

#### í”„ë¡œì íŠ¸ì— ì´ë¯¸ êµ¬í˜„ë¨

**íŒŒì¼**: `hy3dgen/shapegen/pipelines.py` (line 258-298)
```python
def enable_flashvdm(
    self,
    enabled: bool = True,
    adaptive_kv_selection=True,
    topk_mode='mean',
    mc_algo='mc',
    replace_vae=True,
):
    """
    FlashVDM ìµœì í™” í™œì„±í™”
    - VAE Decoder ìµœì í™”
    - Adaptive KV Selection (ë©”ëª¨ë¦¬ ì ˆì•½)
    - Top-K Mode: 'mean' ë˜ëŠ” 'merge'
    """
```

**ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ**:

1. **multiview.py** (line 135-139)
```python
if USE_FLASH_VDM:
    print("  âš¡ FlashVDM ìµœì í™” í™œì„±í™” ì¤‘...")
    shape_pipeline.enable_flashvdm()
    print("  âœ“ FlashVDM í™œì„±í™” ì™„ë£Œ (ì†ë„ í–¥ìƒ)")
```

2. **gradio_app.py** (line 732-734)
```python
if args.enable_flashvdm:
    mc_algo = 'mc' if args.device in ['cpu', 'mps'] else args.mc_algo
    i23d_worker.enable_flashvdm(mc_algo=mc_algo)
```

3. **faster_shape_gen_with_flashvdm_mini_turbo.py** (line 18)
```python
pipeline.enable_flashvdm(topk_mode='merge')
```

#### âœ… color.pyì— ì ìš© ë°©ë²•

```python
# color.py (line 75-80 ìˆ˜ì •)
shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(
    'tencent/Hunyuan3D-2',
    subfolder='hunyuan3d-dit-v2-0-turbo',
    torch_dtype=torch.float16
)

# âœ… FlashVDM ìµœì í™” í™œì„±í™”
print("  âš¡ FlashVDM ìµœì í™” í™œì„±í™” ì¤‘...")
shape_pipeline.enable_flashvdm(
    enabled=True,
    topk_mode='mean',  # 'mean' ë˜ëŠ” 'merge' (mergeê°€ ë” ë¹ ë¦„)
    mc_algo='mc'       # Marching Cubes ì•Œê³ ë¦¬ì¦˜
)
print("  âœ“ FlashVDM í™œì„±í™” ì™„ë£Œ!")

shape_pipeline.to('cuda')
```

#### ì˜ˆìƒ íš¨ê³¼

| í•­ëª© | ê¸°ë³¸ê°’ | FlashVDM | ê°œì„ ìœ¨ |
|------|--------|----------|--------|
| **í˜•ìƒ ìƒì„± ì‹œê°„** | 10-12ì´ˆ | 6-8ì´ˆ | **30-40% ë‹¨ì¶•** |
| **VRAM ì‚¬ìš©ëŸ‰** | 3-4 GB | 2.5-3 GB | **~0.5-1 GB ì ˆì•½** |
| **í’ˆì§ˆ** | 100% | 98-99% | ê±°ì˜ ë™ì¼ |

**ì ìš© ë‚œì´ë„**: ë§¤ìš° ì‰¬ì›€ â­  
**ê¶Œì¥ë„**: â­â­â­â­â­ (ë°˜ë“œì‹œ ì ìš©!)

---

### 2. ğŸ”§ **Torch Compile** (í˜•ìƒ ìƒì„± ìµœì í™”) â­â­â­â­

#### í˜„ì¬ ìƒíƒœ
```python
# color.py
shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(...)
shape_pipeline.to('cuda')
# âŒ Torch Compile ë¯¸ì‚¬ìš©
```

#### í”„ë¡œì íŠ¸ì— ì´ë¯¸ êµ¬í˜„ë¨

**íŒŒì¼**: `hy3dgen/shapegen/pipelines.py` (line 253-256)
```python
def compile(self):
    self.vae = torch.compile(self.vae)
    self.model = torch.compile(self.model)
    self.conditioner = torch.compile(self.conditioner)
```

**ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ**:

1. **gradio_app.py** (line 735-736)
```python
if args.compile:
    i23d_worker.compile()
```

2. **faster_shape_gen_with_flashvdm_mini_turbo.py** (line 19, ì£¼ì„ ì²˜ë¦¬ë¨)
```python
# pipeline.compile()
```

#### âœ… color.pyì— ì ìš© ë°©ë²•

```python
# color.py (line 75-80 ìˆ˜ì •)
shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(
    'tencent/Hunyuan3D-2',
    subfolder='hunyuan3d-dit-v2-0-turbo',
    torch_dtype=torch.float16
)

# âœ… FlashVDM í™œì„±í™”
shape_pipeline.enable_flashvdm(topk_mode='mean')

# âœ… Torch Compile í™œì„±í™” (PyTorch 2.0+)
if hasattr(shape_pipeline, 'compile'):
    print("  ğŸ”¥ ëª¨ë¸ ì»´íŒŒì¼ ì¤‘... (ìµœì´ˆ 1íšŒë§Œ, 30ì´ˆ ì†Œìš”)")
    shape_pipeline.compile()
    print("  âœ“ ì»´íŒŒì¼ ì™„ë£Œ! (ë‹¤ìŒ ì‹¤í–‰ë¶€í„° ë¹ ë¦„)")

shape_pipeline.to('cuda')
```

#### ì˜ˆìƒ íš¨ê³¼

| ì‹¤í–‰ | í˜•ìƒ ìƒì„± ì‹œê°„ | ì„¤ëª… |
|------|---------------|------|
| **1íšŒì°¨** | 40-50ì´ˆ | ì»´íŒŒì¼ ì˜¤ë²„í—¤ë“œ (+30ì´ˆ) |
| **2íšŒì°¨~** | 6-7ì´ˆ | 20-30% ë¹ ë¦„ |

**ì ìš© ë‚œì´ë„**: ì‰¬ì›€ â­â­  
**ê¶Œì¥ë„**: â­â­â­â­ (ë°˜ë³µ ì‹¤í–‰ ì‹œ íš¨ê³¼ì !)

**âš ï¸ ì£¼ì˜ì‚¬í•­**:
- ì²« ì‹¤í–‰ì´ ëŠë¦¼ (ì»´íŒŒì¼ ì‹œê°„)
- 1íšŒë§Œ ì‹¤í–‰í•˜ëŠ” ê²½ìš° ì˜¤íˆë ¤ ëŠë¦´ ìˆ˜ ìˆìŒ
- ë°°ì¹˜ ì²˜ë¦¬ë‚˜ ë°˜ë³µ ì‹¤í–‰ ì‹œ ê¶Œì¥

---

### 3. ğŸ’¾ **CPU ì˜¤í”„ë¡œë”©** (í…ìŠ¤ì²˜ ìƒì„± ë©”ëª¨ë¦¬ ì ˆì•½) â­â­â­â­â­

#### í˜„ì¬ ìƒíƒœ
```python
# color.py (line 137-143)
paint_pipeline = Hunyuan3DPaintPipeline.from_pretrained(
    'tencent/Hunyuan3D-2',
    subfolder='hunyuan3d-paint-v2-0-turbo'
)

# âš¡ ì¤‘ìš”: í…ìŠ¤ì²˜ ìƒì„± ëª¨ë¸ë“¤ì„ GPUë¡œ ì´ë™
print("  - ëª¨ë¸ì„ GPUë¡œ ì´ë™ ì¤‘...")
paint_pipeline.models['delight_model'].pipeline.to('cuda')
paint_pipeline.models['multiview_model'].pipeline.to('cuda')
# âŒ CPU ì˜¤í”„ë¡œë”© ë¯¸ì‚¬ìš© (ë©”ëª¨ë¦¬ ë‚­ë¹„)
```

#### í”„ë¡œì íŠ¸ì— ì´ë¯¸ êµ¬í˜„ë¨

**íŒŒì¼**: `hy3dgen/texgen/pipelines.py` (line 106-108)
```python
def enable_model_cpu_offload(self, gpu_id: Optional[int] = None, device: Union[torch.device, str] = "cuda"):
    self.models['delight_model'].pipeline.enable_model_cpu_offload(gpu_id=gpu_id, device=device)
    self.models['multiview_model'].pipeline.enable_model_cpu_offload(gpu_id=gpu_id, device=device)
```

**ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ**:

**gradio_app.py** (line 698-699)
```python
if args.low_vram_mode:
    texgen_worker.enable_model_cpu_offload()
```

#### ë™ì‘ ì›ë¦¬

```
ì¼ë°˜ ëª¨ë“œ (í˜„ì¬):
    GPU: [Delight Model 4GB] + [Multiview Model 4GB] = 8GB ë™ì‹œ ì‚¬ìš©
    
CPU ì˜¤í”„ë¡œë”©:
    1ë‹¨ê³„: GPU [Delight Model 4GB] â†’ ì²˜ë¦¬ â†’ CPUë¡œ ì´ë™
    2ë‹¨ê³„: GPU [Multiview Model 4GB] â†’ ì²˜ë¦¬
    
    ê²°ê³¼: GPU í”¼í¬ ë©”ëª¨ë¦¬ ~4GB (ì ˆë°˜!)
```

#### âœ… color.pyì— ì ìš© ë°©ë²•

```python
# color.py (line 137-160 ìˆ˜ì •)

paint_pipeline = Hunyuan3DPaintPipeline.from_pretrained(
    'tencent/Hunyuan3D-2',
    subfolder='hunyuan3d-paint-v2-0-turbo'
)

# âœ… CPU ì˜¤í”„ë¡œë”© í™œì„±í™” (8GB VRAMì—ì„œ í•„ìˆ˜!)
print("  ğŸ’¾ CPU ì˜¤í”„ë¡œë”© í™œì„±í™” ì¤‘... (ë©”ëª¨ë¦¬ ì ˆì•½)")
paint_pipeline.enable_model_cpu_offload()
print("  âœ“ CPU ì˜¤í”„ë¡œë”© ì™„ë£Œ! (~4GB VRAM ì ˆì•½)")

# âŒ ì•„ë˜ ì½”ë“œëŠ” ì‚­ì œ (CPU ì˜¤í”„ë¡œë”©ê³¼ ì¶©ëŒ)
# paint_pipeline.models['delight_model'].pipeline.to('cuda')
# paint_pipeline.models['multiview_model'].pipeline.to('cuda')

paint_pipeline.render.device = torch.device('cuda')
```

#### ì˜ˆìƒ íš¨ê³¼

| í•­ëª© | ê¸°ë³¸ê°’ | CPU ì˜¤í”„ë¡œë”© | ê°œì„ ìœ¨ |
|------|--------|-------------|--------|
| **í…ìŠ¤ì²˜ ìƒì„± VRAM** | 11-12 GB | 7-8 GB | **~4GB ì ˆì•½** |
| **ì‹œê°„ ì˜í–¥** | 420ì´ˆ | 440ì´ˆ | +20ì´ˆ (5%) |
| **ì•ˆì •ì„±** | OOM ìœ„í—˜ | ë§¤ìš° ì•ˆì • | âœ… |

**ì ìš© ë‚œì´ë„**: ë§¤ìš° ì‰¬ì›€ â­  
**ê¶Œì¥ë„**: â­â­â­â­â­ (8GB VRAMì—ì„œ í•„ìˆ˜!)

---

### 4. ğŸ“ **í…ìŠ¤ì²˜ ì¶”ë¡  ë‹¨ê³„ ì „ë‹¬** (ì‚¬ìš©ì ì„¤ì • ì ìš©) â­â­â­â­â­

#### í˜„ì¬ ìƒíƒœ (ë²„ê·¸!)

```python
# color.py (line 105-126)
class CustomTexGenConfig:
    def __init__(self, light_remover_ckpt_path, multiview_ckpt_path, subfolder_name):
        # ... ê¸°íƒ€ ì„¤ì • ...
        self.delight_inference_steps = DELIGHT_INFERENCE_STEPS  # âœ… ì„¤ì •ë¨
        self.multiview_inference_steps = MULTIVIEW_INFERENCE_STEPS  # âœ… ì„¤ì •ë¨
        # ...

# line 137-145
paint_pipeline = Hunyuan3DPaintPipeline.from_pretrained(
    'tencent/Hunyuan3D-2',
    subfolder='hunyuan3d-paint-v2-0-turbo'
)
# âŒ ë¬¸ì œ: CustomTexGenConfigë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ!
#    â†’ delight_inference_steps, multiview_inference_stepsê°€ ì ìš© ì•ˆ ë¨!
```

#### ì‹¤ì œ ë¡œì§ í™•ì¸

**íŒŒì¼**: `hy3dgen/texgen/utils/dehighlight_utils.py` (line 31)
```python
class Light_Shadow_Remover():
    def __init__(self, config):
        # ...
        self.num_inference_steps = getattr(config, 'delight_inference_steps', 6)
        # âŒ color.pyëŠ” ê¸°ë³¸ê°’ 6ì„ ì‚¬ìš© (DELIGHT_INFERENCE_STEPS ë¬´ì‹œ!)
```

**íŒŒì¼**: `hy3dgen/texgen/utils/multiview_utils.py` (line 37)
```python
class Multiview_Diffusion_Net():
    def __init__(self, config) -> None:
        # ...
        self.num_inference_steps = getattr(config, 'multiview_inference_steps', 6)
        # âŒ color.pyëŠ” ê¸°ë³¸ê°’ 6ì„ ì‚¬ìš© (MULTIVIEW_INFERENCE_STEPS ë¬´ì‹œ!)
```

#### ë¬¸ì œì 

ì‚¬ìš©ìê°€ ì„¤ì •í•œ `DELIGHT_INFERENCE_STEPS`ì™€ `MULTIVIEW_INFERENCE_STEPS` ê°’ì´ **ì‹¤ì œë¡œëŠ” ì ìš©ë˜ì§€ ì•Šê³  ìˆìŠµë‹ˆë‹¤!**

```python
# ì‚¬ìš©ìê°€ ì´ë ‡ê²Œ ì„¤ì •í•´ë„...
DELIGHT_INFERENCE_STEPS = 4     # ë¹ ë¥´ê²Œ!
MULTIVIEW_INFERENCE_STEPS = 4   # ë¹ ë¥´ê²Œ!

# ì‹¤ì œë¡œëŠ” ê¸°ë³¸ê°’ 6ì´ ì‚¬ìš©ë¨ (CustomTexGenConfig ë¯¸ì‚¬ìš©)
```

#### âœ… color.py ìˆ˜ì • ë°©ë²•

**í˜„ì¬ ì½”ë“œë¥¼ ìœ ì§€í•˜ë˜, CustomTexGenConfig ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •**

```python
# color.py (line 105-145 ì „ì²´ êµì²´)

# íŒŒì´í”„ë¼ì¸ ì„¤ì •ì„ ìœ„í•œ ì»¤ìŠ¤í…€ config í´ë˜ìŠ¤
class CustomTexGenConfig:
    def __init__(self, light_remover_ckpt_path, multiview_ckpt_path, subfolder_name):
        self.device = 'cuda'
        self.light_remover_ckpt_path = light_remover_ckpt_path
        self.multiview_ckpt_path = multiview_ckpt_path
        self.candidate_camera_azims = camera_azims
        self.candidate_camera_elevs = camera_elevs
        self.candidate_view_weights = view_weights
        self.render_size = RENDER_SIZE
        self.texture_size = TEXTURE_SIZE
        self.delight_inference_steps = DELIGHT_INFERENCE_STEPS  # âœ… ì‚¬ìš©ì ì„¤ì •
        self.multiview_inference_steps = MULTIVIEW_INFERENCE_STEPS  # âœ… ì‚¬ìš©ì ì„¤ì •
        self.bake_exp = 4
        self.merge_method = 'fast'
        self.pipe_dict = {'hunyuan3d-paint-v2-0': 'hunyuanpaint', 'hunyuan3d-paint-v2-0-turbo': 'hunyuanpaint-turbo'}
        self.pipe_name = self.pipe_dict[subfolder_name]

# âœ… ìˆ˜ì •: CustomTexGenConfigë¥¼ ì‹¤ì œë¡œ ì‚¬ìš©
from pathlib import Path
model_path = Path.home() / '.cache/hy3dgen/tencent/Hunyuan3D-2'
delight_path = str(model_path / 'hunyuan3d-delight-v2-0')
multiview_path = str(model_path / 'hunyuan3d-paint-v2-0-turbo')

# âœ… ì»¤ìŠ¤í…€ configë¡œ íŒŒì´í”„ë¼ì¸ ìƒì„±
custom_config = CustomTexGenConfig(delight_path, multiview_path, 'hunyuan3d-paint-v2-0-turbo')
paint_pipeline = Hunyuan3DPaintPipeline(custom_config)

# âœ… CPU ì˜¤í”„ë¡œë”© (8GB VRAM í•„ìˆ˜)
paint_pipeline.enable_model_cpu_offload()
paint_pipeline.render.device = torch.device('cuda')
```

#### ì˜ˆìƒ íš¨ê³¼

**í˜„ì¬ (ë²„ê·¸ ìƒíƒœ)**:
```
ì‚¬ìš©ì ì„¤ì •: DELIGHT_INFERENCE_STEPS = 4
ì‹¤ì œ ì‚¬ìš©: 6 (ê¸°ë³¸ê°’)
â†’ ì‚¬ìš©ìê°€ ì„¤ì •ì„ ë°”ê¿”ë„ íš¨ê³¼ ì—†ìŒ!
```

**ìˆ˜ì • í›„**:
```
ì‚¬ìš©ì ì„¤ì •: DELIGHT_INFERENCE_STEPS = 4
ì‹¤ì œ ì‚¬ìš©: 4 (ì‚¬ìš©ì ì„¤ì • ì ìš©!)
â†’ ì„¤ì •ëŒ€ë¡œ ë¹ ë¥´ê²Œ ì‹¤í–‰ë¨ âœ…
```

| ì„¤ì • | í˜„ì¬ (ë²„ê·¸) | ìˆ˜ì • í›„ |
|------|------------|---------|
| DELIGHT_INFERENCE_STEPS = 4 | 6 ì‚¬ìš© | 4 ì‚¬ìš© âœ… |
| MULTIVIEW_INFERENCE_STEPS = 4 | 6 ì‚¬ìš© | 4 ì‚¬ìš© âœ… |
| ì˜ˆìƒ ì‹œê°„ ì ˆì•½ | 0ì´ˆ | **~80-100ì´ˆ** |

**ì ìš© ë‚œì´ë„**: ì¤‘ê°„ â­â­â­  
**ê¶Œì¥ë„**: â­â­â­â­â­ (ë²„ê·¸ ìˆ˜ì • í•„ìˆ˜!)

---

## ğŸ“Š í†µí•© ì ìš© ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ A: **ìµœì†Œ ë³€ê²½ (FlashVDMë§Œ)** â­â­â­â­

#### ì ìš© ë‚´ìš©
```python
# í˜•ìƒ ìƒì„± ë¶€ë¶„
shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(...)
shape_pipeline.enable_flashvdm(topk_mode='mean')  # âœ… ì¶”ê°€
shape_pipeline.to('cuda')
```

**ì˜ˆìƒ íš¨ê³¼**:
- í˜•ìƒ ìƒì„±: 10ì´ˆ â†’ 6-7ì´ˆ (30% ë¹ ë¦„)
- VRAM: -0.5GB
- ì ìš© ì‹œê°„: 1ë¶„

---

### ì‹œë‚˜ë¦¬ì˜¤ B: **ê¶Œì¥ ì„¤ì • (FlashVDM + CPU ì˜¤í”„ë¡œë”©)** â­â­â­â­â­

#### ì ìš© ë‚´ìš©
```python
# 1. í˜•ìƒ ìƒì„±
shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(...)
shape_pipeline.enable_flashvdm(topk_mode='mean')  # âœ… ì¶”ê°€
shape_pipeline.to('cuda')

# 2. í…ìŠ¤ì²˜ ìƒì„±
paint_pipeline = Hunyuan3DPaintPipeline.from_pretrained(...)
paint_pipeline.enable_model_cpu_offload()  # âœ… ì¶”ê°€
paint_pipeline.render.device = torch.device('cuda')
```

**ì˜ˆìƒ íš¨ê³¼**:
- í˜•ìƒ ìƒì„±: 10ì´ˆ â†’ 6-7ì´ˆ
- í…ìŠ¤ì²˜ VRAM: 12GB â†’ 7-8GB (8GBì—ì„œ ì‹¤í–‰ ê°€ëŠ¥!)
- ì´ ì‹œê°„: +20ì´ˆ (ì•ˆì •ì„± >> ì†ë„)
- ì ìš© ì‹œê°„: 5ë¶„

---

### ì‹œë‚˜ë¦¬ì˜¤ C: **ìµœëŒ€ ìµœì í™” (ëª¨ë“  ê¸°ëŠ¥)** â­â­â­â­â­

#### ì ìš© ë‚´ìš©
```python
# 1. í˜•ìƒ ìƒì„±
shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(...)
shape_pipeline.enable_flashvdm(topk_mode='mean')  # âœ… ì¶”ê°€
shape_pipeline.compile()  # âœ… ì¶”ê°€ (PyTorch 2.0+)
shape_pipeline.to('cuda')

# 2. í…ìŠ¤ì²˜ ìƒì„± (CustomTexGenConfig ì‚¬ìš©)
custom_config = CustomTexGenConfig(...)  # âœ… ë²„ê·¸ ìˆ˜ì •
paint_pipeline = Hunyuan3DPaintPipeline(custom_config)
paint_pipeline.enable_model_cpu_offload()  # âœ… ì¶”ê°€
paint_pipeline.render.device = torch.device('cuda')
```

**ì˜ˆìƒ íš¨ê³¼**:
- í˜•ìƒ ìƒì„± (1íšŒì°¨): 40ì´ˆ (ì»´íŒŒì¼)
- í˜•ìƒ ìƒì„± (2íšŒì°¨~): 5-6ì´ˆ (40% ë¹ ë¦„!)
- í…ìŠ¤ì²˜ VRAM: 7-8GB
- ì‚¬ìš©ì ì„¤ì • ì ìš©: âœ… (ë²„ê·¸ ìˆ˜ì •)
- ì ìš© ì‹œê°„: 10-15ë¶„

---

## ğŸ¯ ìµœì¢… ê¶Œì¥ ì‚¬í•­

### ì¦‰ì‹œ ì ìš© (í•„ìˆ˜) â­â­â­â­â­

1. **FlashVDM** - 1ì¤„ ì¶”ê°€
2. **CPU ì˜¤í”„ë¡œë”©** - 1ì¤„ ì¶”ê°€
3. **ë²„ê·¸ ìˆ˜ì •** (CustomTexGenConfig) - ì½”ë“œ ì¬êµ¬ì„±

**ì´ìœ **:
- 8GB VRAMì—ì„œ ì•ˆì • ì‹¤í–‰
- í˜•ìƒ ìƒì„± 30% ë¹ ë¦„
- ì‚¬ìš©ì ì„¤ì •ì´ ì‹¤ì œë¡œ ì ìš©ë¨

### ì„ íƒ ì ìš© (ë°˜ë³µ ì‹¤í–‰ ì‹œ) â­â­â­â­

4. **Torch Compile** - 1ì¤„ ì¶”ê°€

**ì´ìœ **:
- ì²« ì‹¤í–‰ ëŠë¦¼ (ì»´íŒŒì¼)
- ë°˜ë³µ ì‹¤í–‰ ì‹œ 20-30% ë¹ ë¦„

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Phase 1: ì¦‰ì‹œ ì ìš© (5ë¶„)

- [ ] `shape_pipeline.enable_flashvdm(topk_mode='mean')` ì¶”ê°€
- [ ] `paint_pipeline.enable_model_cpu_offload()` ì¶”ê°€
- [ ] `paint_pipeline.models[...].to('cuda')` ì‚­ì œ (ì¶©ëŒ ë°©ì§€)

**ì˜ˆìƒ íš¨ê³¼**: í˜•ìƒ 30% ë¹ ë¦„, VRAM ~4GB ì ˆì•½

---

### Phase 2: ë²„ê·¸ ìˆ˜ì • (10ë¶„)

- [ ] CustomTexGenConfig ì‚¬ìš©í•˜ë„ë¡ ì½”ë“œ ì¬êµ¬ì„±
- [ ] ëª¨ë¸ ê²½ë¡œ í™•ì¸ (~/.cache/hy3dgen/...)
- [ ] í…ŒìŠ¤íŠ¸: DELIGHT_INFERENCE_STEPS = 4ë¡œ ë³€ê²½ ì‹œ ì‹¤ì œ ì ìš©ë˜ëŠ”ì§€ í™•ì¸

**ì˜ˆìƒ íš¨ê³¼**: ì‚¬ìš©ì ì„¤ì • ì •ìƒ ë™ì‘

---

### Phase 3: ì„ íƒ ì‚¬í•­ (5ë¶„)

- [ ] `shape_pipeline.compile()` ì¶”ê°€ (ë°˜ë³µ ì‹¤í–‰ ì‹œë§Œ)
- [ ] ì²« ì‹¤í–‰ ì»´íŒŒì¼ ì‹œê°„ ì¸¡ì • (~30ì´ˆ)
- [ ] ë‘ ë²ˆì§¸ ì‹¤í–‰ ì‹œê°„ ë¹„êµ

**ì˜ˆìƒ íš¨ê³¼**: 2íšŒì°¨ë¶€í„° 20-30% ë¹ ë¦„

---

## ğŸš¨ ì£¼ì˜ì‚¬í•­

### 1. CPU ì˜¤í”„ë¡œë”© + .to('cuda') ì¶©ëŒ

**ì˜ëª»ëœ ì½”ë“œ**:
```python
paint_pipeline.enable_model_cpu_offload()  # CPU ì˜¤í”„ë¡œë”©
paint_pipeline.models['delight_model'].pipeline.to('cuda')  # âŒ ì¶©ëŒ!
```

**ì˜¬ë°”ë¥¸ ì½”ë“œ**:
```python
paint_pipeline.enable_model_cpu_offload()  # CPU ì˜¤í”„ë¡œë”©ë§Œ
paint_pipeline.render.device = torch.device('cuda')  # Rendererë§Œ GPU
```

### 2. CustomTexGenConfig ê²½ë¡œ ë¬¸ì œ

ëª¨ë¸ì´ ë‹¤ìš´ë¡œë“œëœ ì‹¤ì œ ê²½ë¡œë¥¼ í™•ì¸í•´ì•¼ í•©ë‹ˆë‹¤:

```python
# ê°€ëŠ¥í•œ ê²½ë¡œë“¤
~/.cache/hy3dgen/tencent/Hunyuan3D-2/
~/.cache/huggingface/hub/models--tencent--Hunyuan3D-2/
/path/to/local/models/
```

ê²½ë¡œê°€ í‹€ë¦¬ë©´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨!

### 3. Torch Compile í™˜ê²½ ìš”êµ¬ì‚¬í•­

- PyTorch 2.0 ì´ìƒ í•„ìš”
- CUDA 11.8 ì´ìƒ ê¶Œì¥
- ì²« ì‹¤í–‰ ì‹œ ~30ì´ˆ ì»´íŒŒì¼ ì‹œê°„

---

## ğŸ“š ì°¸ê³  íŒŒì¼

1. **gradio_app.py**: CPU ì˜¤í”„ë¡œë”©, Compile ì˜ˆì‹œ
2. **multiview.py**: FlashVDM ì‚¬ìš© ì˜ˆì‹œ
3. **hy3dgen/shapegen/pipelines.py**: enable_flashvdm(), compile() êµ¬í˜„
4. **hy3dgen/texgen/pipelines.py**: enable_model_cpu_offload() êµ¬í˜„

---

## ğŸ ë³´ë„ˆìŠ¤: ì™„ì „ ìµœì í™”ëœ color.py ìŠ¤ë‹ˆí«

```python
# ==== color.py ìµœì í™” ë²„ì „ ====

import torch
import os
from pathlib import Path
from PIL import Image
from hy3dgen.texgen import Hunyuan3DPaintPipeline
from hy3dgen.shapegen import Hunyuan3DDiTFlowMatchingPipeline
from hy3dgen.rembg import BackgroundRemover

# ... ì„¤ì • íŒŒë¼ë¯¸í„° ìƒëµ ...

# ==========================================
# 1. í˜•ìƒ ìƒì„± íŒŒì´í”„ë¼ì¸ (ìµœì í™”)
# ==========================================
print("í˜•ìƒ ìƒì„± íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì¤‘...")
shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(
    'tencent/Hunyuan3D-2',
    subfolder='hunyuan3d-dit-v2-0-turbo',
    torch_dtype=torch.float16
)

# âœ… FlashVDM í™œì„±í™” (30% ì†ë„ í–¥ìƒ)
print("  âš¡ FlashVDM ìµœì í™” í™œì„±í™”...")
shape_pipeline.enable_flashvdm(topk_mode='mean')

# âœ… Torch Compile (ì„ íƒ, ë°˜ë³µ ì‹¤í–‰ ì‹œ)
if hasattr(shape_pipeline, 'compile'):
    print("  ğŸ”¥ ëª¨ë¸ ì»´íŒŒì¼ ì¤‘... (ìµœì´ˆ 1íšŒë§Œ)")
    shape_pipeline.compile()

shape_pipeline.to('cuda')
print("âœ… í˜•ìƒ íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ì™„ë£Œ!")

# ==========================================
# 2. í…ìŠ¤ì²˜ ìƒì„± íŒŒì´í”„ë¼ì¸ (ìµœì í™”)
# ==========================================
print("\ní…ìŠ¤ì²˜ ìƒì„± íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì¤‘...")

# ì¹´ë©”ë¼ ë·° ì„¤ì •
if CAMERA_VIEWS == 'minimal':
    camera_azims = [0, 120, 240]
    camera_elevs = [0, 0, 0]
    view_weights = [1, 0.3, 0.3]
elif CAMERA_VIEWS == 'fast':
    camera_azims = [0, 90, 180, 270]
    camera_elevs = [0, 0, 0, 0]
    view_weights = [1, 0.1, 0.5, 0.1]
else:  # standard
    camera_azims = [0, 90, 180, 270, 0, 180]
    camera_elevs = [0, 0, 0, 0, 90, -90]
    view_weights = [1, 0.1, 0.5, 0.1, 0.05, 0.05]

# âœ… CustomTexGenConfigë¡œ ì‚¬ìš©ì ì„¤ì • ì ìš© (ë²„ê·¸ ìˆ˜ì •)
class CustomTexGenConfig:
    def __init__(self, light_remover_ckpt_path, multiview_ckpt_path, subfolder_name):
        self.device = 'cuda'
        self.light_remover_ckpt_path = light_remover_ckpt_path
        self.multiview_ckpt_path = multiview_ckpt_path
        self.candidate_camera_azims = camera_azims
        self.candidate_camera_elevs = camera_elevs
        self.candidate_view_weights = view_weights
        self.render_size = RENDER_SIZE
        self.texture_size = TEXTURE_SIZE
        self.delight_inference_steps = DELIGHT_INFERENCE_STEPS  # âœ… ì ìš©ë¨
        self.multiview_inference_steps = MULTIVIEW_INFERENCE_STEPS  # âœ… ì ìš©ë¨
        self.bake_exp = 4
        self.merge_method = 'fast'
        self.pipe_dict = {
            'hunyuan3d-paint-v2-0': 'hunyuanpaint',
            'hunyuan3d-paint-v2-0-turbo': 'hunyuanpaint-turbo'
        }
        self.pipe_name = self.pipe_dict[subfolder_name]

# ëª¨ë¸ ê²½ë¡œ ìë™ íƒì§€
model_base = Path.home() / '.cache/hy3dgen/tencent/Hunyuan3D-2'
if not model_base.exists():
    # Hugging Face ê¸°ë³¸ ê²½ë¡œ
    model_base = Path.home() / '.cache/huggingface/hub/models--tencent--Hunyuan3D-2'

delight_path = str(model_base / 'hunyuan3d-delight-v2-0')
multiview_path = str(model_base / 'hunyuan3d-paint-v2-0-turbo')

custom_config = CustomTexGenConfig(delight_path, multiview_path, 'hunyuan3d-paint-v2-0-turbo')
paint_pipeline = Hunyuan3DPaintPipeline(custom_config)

# âœ… CPU ì˜¤í”„ë¡œë”© (8GB VRAM í•„ìˆ˜!)
print("  ğŸ’¾ CPU ì˜¤í”„ë¡œë”© í™œì„±í™”... (~4GB VRAM ì ˆì•½)")
paint_pipeline.enable_model_cpu_offload()
paint_pipeline.render.device = torch.device('cuda')

print("âœ… í…ìŠ¤ì²˜ íŒŒì´í”„ë¼ì¸ ì¤€ë¹„ ì™„ë£Œ!")

# ... ë‚˜ë¨¸ì§€ ì½”ë“œ ë™ì¼ ...
```

---

**ì‘ì„±ì¼**: 2025-11-02  
**ë¶„ì„ ëŒ€ìƒ**: color.py (í˜„ì¬ ì‹¤í–‰ ì¤‘ì¸ ì½”ë“œ)  
**ë¹„êµ ëŒ€ìƒ**: gradio_app.py, multiview.py, pipelines.py  
**ëª©ì **: ì´ë¯¸ êµ¬í˜„ëœ ìµœì í™” ê¸°ëŠ¥ í™œìš©

