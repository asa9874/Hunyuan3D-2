import torch
import os
import time
from datetime import datetime
from PIL import Image
from hy3dgen.texgen import Hunyuan3DPaintPipeline
from hy3dgen.shapegen import Hunyuan3DDiTFlowMatchingPipeline
from hy3dgen.rembg import BackgroundRemover

# CUDA/cuDNN ì´ˆê¸°í™” ë° í™˜ê²½ ì„¤ì •
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # CUDA ë™ê¸°í™” ëª¨ë“œ
torch.backends.cudnn.enabled = False  # cuDNN ë¹„í™œì„±í™” (ì´ˆê¸°í™” ì˜¤ë¥˜ ë°©ì§€)
torch.backends.cudnn.benchmark = False
torch.backends.cuda.matmul.allow_tf32 = True

# CUDA ì¥ì¹˜ í™•ì¸ ë° ì´ˆê¸°í™”
if torch.cuda.is_available():
    torch.cuda.init()
    print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}")
    print(f"CUDA ë²„ì „: {torch.version.cuda}")
    print(f"cuDNN í™œì„±í™”: {torch.backends.cudnn.enabled}")
    # ì´ˆê¸° GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    torch.cuda.empty_cache()
    torch.cuda.reset_peak_memory_stats()
else:
    print("âš ï¸ CUDAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPU ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
    exit(1)

# ==== ì„¤ì • ê°€ëŠ¥í•œ ë§¤ê°œë³€ìˆ˜ ====
# ê²½ë¡œ ì„¤ì • - ë©€í‹°ë·° ì´ë¯¸ì§€ (ìµœì†Œ 2ê°œ, ê¶Œì¥ 3-4ê°œ)
INPUT_IMAGES = {
    "front": "mymv/input/front.png",      # í•„ìˆ˜: ì •ë©´
    #"left": "mymv/input/left.png",        # ì„ íƒ: ì¢Œì¸¡
    "back": "mymv/input/back.png",        # ì„ íƒ: í›„ë©´
    # "right": "mymv/input/right.png",    # ì„ íƒ: ìš°ì¸¡
}

# ë°°ê²½ ì œê±° ì„¤ì •
REMOVE_BACKGROUND = True            # ë°°ê²½ ì œê±° í™œì„±í™” (True/False)

# í˜•ìƒ ìƒì„± í’ˆì§ˆ ì„¤ì • (MultiView ëª¨ë¸)
NUM_INFERENCE_STEPS = 5             # í˜•ìƒ ìƒì„± ì¶”ë¡  ë‹¨ê³„ (ê¸°ë³¸: 5, ë²”ìœ„: 3-10)
OCTREE_RESOLUTION = 380             # Octree í•´ìƒë„ (256=ë¹ ë¦„, 380=ê· í˜•, 512=ëŠë¦¼/ê³ í’ˆì§ˆ)
NUM_CHUNKS = 20000                  # ì²­í¬ ìˆ˜ (ë©”ëª¨ë¦¬ ê´€ë¦¬, ê¸°ë³¸: 20000)
GUIDANCE_SCALE = 5                  # ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼ (ê¸°ë³¸: 5, ë²”ìœ„: 3-10)
USE_FLASH_VDM = True                # FlashVDM ìµœì í™” (ì†ë„ í–¥ìƒ)

# í…ìŠ¤ì²˜ ìƒì„± í’ˆì§ˆ ì„¤ì •
DELIGHT_INFERENCE_STEPS = 6         # ê·¸ë¦¼ì ì œê±° ì¶”ë¡  ë‹¨ê³„ (ê¸°ë³¸: 6, ë²”ìœ„: 4-10)
MULTIVIEW_INFERENCE_STEPS = 6       # ë©€í‹°ë·° ìƒì„± ì¶”ë¡  ë‹¨ê³„ (ê¸°ë³¸: 6, ë²”ìœ„: 4-10)

# ì¹´ë©”ë¼ ë·° ì„¤ì • (í…ìŠ¤ì²˜ ìƒì„± ì‹œ)
CAMERA_VIEWS = 'standard'           # 'standard'(6ë·°,ëŠë¦¼), 'fast'(4ë·°,ë¹ ë¦„), 'minimal'(3ë·°,ë§¤ìš°ë¹ ë¦„)

# ë Œë”ë§ ì„¤ì •
RENDER_SIZE = 2048                  # ë Œë” í•´ìƒë„ (1024=ë¹ ë¦„, 2048=ê¸°ë³¸, 4096=ê³ í’ˆì§ˆ/ëŠë¦¼)
TEXTURE_SIZE = 2048                 # í…ìŠ¤ì²˜ í•´ìƒë„ (1024, 2048, 4096)
# ============================

# ì¶œë ¥ íŒŒì¼ëª… ì„¤ì •
output_basename = 'multiview_model'
OUTPUT_PATH = f'mymv/output/{output_basename}.glb'

# ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì„¤ì •
log_dir = 'mymv/log'
os.makedirs(log_dir, exist_ok=True)
os.makedirs('mymv/output', exist_ok=True)
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
LOG_PATH = os.path.join(log_dir, f'{timestamp}_{output_basename}.txt')

# ì‹œê°„ ì¸¡ì •ì„ ìœ„í•œ ë³€ìˆ˜
time_records = {}
start_total = time.time()  # ì „ì²´ ì‹œì‘ ì‹œê°„

# 0. ë©€í‹°ë·° ì´ë¯¸ì§€ ë¡œë“œ ë° ë°°ê²½ ì œê±°
print("=" * 60)
print("ë©€í‹°ë·° ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
print(f"  - ì…ë ¥ ì´ë¯¸ì§€ ê°œìˆ˜: {len(INPUT_IMAGES)}ê°œ")
start_time = time.time()

processed_images = {}
for view_name, image_path in INPUT_IMAGES.items():
    if not os.path.exists(image_path):
        print(f"  âš ï¸  ê²½ê³ : '{image_path}' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ì´ ë·°ëŠ” ê±´ë„ˆëœë‹ˆë‹¤.")
        continue
    
    print(f"  - ì²˜ë¦¬ ì¤‘: {view_name} ({os.path.basename(image_path)})")
    image = Image.open(image_path)
    original_mode = image.mode
    print(f"    ì›ë³¸ ëª¨ë“œ: {original_mode}")
    
    # ë°°ê²½ ì œê±° ìˆ˜í–‰ ì—¬ë¶€ ê²°ì •
    if REMOVE_BACKGROUND and original_mode in ['RGB', 'L']:
        print(f"    ë°°ê²½ ì œê±° ìˆ˜í–‰ ì¤‘...")
        if original_mode == 'L':
            image = image.convert('RGB')
        rembg = BackgroundRemover()
        image = rembg(image)
        print(f"    ë°°ê²½ ì œê±° ì™„ë£Œ!")
    elif REMOVE_BACKGROUND and original_mode == 'RGBA':
        print(f"    ì´ë¯¸ ì•ŒíŒŒ ì±„ë„ ì¡´ì¬")
    else:
        image = image.convert("RGBA")
    
    processed_images[view_name] = image

if len(processed_images) < 2:
    print("\nâŒ ì˜¤ë¥˜: ìµœì†Œ 2ê°œ ì´ìƒì˜ ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    print("   (ê¶Œì¥: front, left, back 3ê°œ)")
    exit(1)

print(f"\nâœ“ {len(processed_images)}ê°œ ë·° ì²˜ë¦¬ ì™„ë£Œ: {list(processed_images.keys())}")
time_records['ì´ë¯¸ì§€ ì „ì²˜ë¦¬'] = time.time() - start_time
print(f"ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time_records['ì´ë¯¸ì§€ ì „ì²˜ë¦¬']:.2f}ì´ˆ)")
print("=" * 60)

# 1. ë©€í‹°ë·° í˜•ìƒ(Shape) ìƒì„± íŒŒì´í”„ë¼ì¸ ë¡œë“œ
print("\n" + "=" * 60)
print("ë©€í‹°ë·° í˜•ìƒ ìƒì„± íŒŒì´í”„ë¼ì¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
print("  ğŸ“¦ ëª¨ë¸: Hunyuan3D-DiT-v2-mv-Turbo")
start_time = time.time()

try:
    shape_pipeline = Hunyuan3DDiTFlowMatchingPipeline.from_pretrained(
        'tencent/Hunyuan3D-2mv',
        subfolder='hunyuan3d-dit-v2-mv-turbo',
        torch_dtype=torch.float16,
        variant='fp16'
    )
    
    # GPUë¡œ ëª…ì‹œì ìœ¼ë¡œ ì´ë™
    print("  - ëª¨ë¸ì„ GPUë¡œ ì´ë™ ì¤‘...")
    shape_pipeline.to('cuda')
    
    # FlashVDM ìµœì í™” í™œì„±í™”
    if USE_FLASH_VDM:
        print("  âš¡ FlashVDM ìµœì í™” í™œì„±í™” ì¤‘...")
        shape_pipeline.enable_flashvdm()
        print("  âœ“ FlashVDM í™œì„±í™” ì™„ë£Œ (ì†ë„ í–¥ìƒ)")
    
    # GPU ë©”ëª¨ë¦¬ ìƒíƒœ í™•ì¸
    if torch.cuda.is_available():
        torch.cuda.empty_cache()  # GPU ìºì‹œ ì •ë¦¬
        torch.cuda.synchronize()
        gpu_mem = torch.cuda.memory_allocated() / 1024**3
        print(f"  - GPU ë©”ëª¨ë¦¬ ì‚¬ìš©: {gpu_mem:.2f} GB")
    
    time_records['íŒŒì´í”„ë¼ì¸ ë¡œë“œ'] = time.time() - start_time
    print(f"ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time_records['íŒŒì´í”„ë¼ì¸ ë¡œë“œ']:.2f}ì´ˆ)")
    print("=" * 60)
    
except Exception as e:
    print(f"\nâŒ íŒŒì´í”„ë¼ì¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    print("\nğŸ’¡ í•´ê²° ë°©ë²•:")
    print("  1. CUDA ë“œë¼ì´ë²„ ì—…ë°ì´íŠ¸")
    print("  2. PyTorch ì¬ì„¤ì¹˜: pip install torch --upgrade --force-reinstall")
    print("  3. cuDNN ì¬ì„¤ì¹˜")
    print("  4. ì‹œìŠ¤í…œ ì¬ë¶€íŒ… í›„ ì¬ì‹œë„")
    exit(1)

# 2. ë©€í‹°ë·° ì´ë¯¸ì§€ë¡œë¶€í„° 3D í˜•ìƒ ìƒì„±
print("\n" + "=" * 60)
print(f"ë©€í‹°ë·° ì´ë¯¸ì§€ë¡œë¶€í„° 3D ëª¨ë¸ í˜•ìƒì„ ìƒì„±í•©ë‹ˆë‹¤...")
print(f"  - ì…ë ¥ ë·°: {list(processed_images.keys())}")
print(f"  - ì¶”ë¡  ë‹¨ê³„: {NUM_INFERENCE_STEPS}")
print(f"  - Octree í•´ìƒë„: {OCTREE_RESOLUTION}")
print(f"  - ì²­í¬ ìˆ˜: {NUM_CHUNKS}")
print(f"  - ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼: {GUIDANCE_SCALE}")

# GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ìƒíƒœ í™•ì¸
if torch.cuda.is_available():
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
    gpu_mem_before_shape = torch.cuda.memory_allocated() / 1024**3
    print(f"  - ì‹œì‘ ì „ GPU ë©”ëª¨ë¦¬: {gpu_mem_before_shape:.2f} GB")

start_time = time.time()

try:
    mesh = shape_pipeline(
        image=processed_images,
        num_inference_steps=NUM_INFERENCE_STEPS,
        octree_resolution=OCTREE_RESOLUTION,
        num_chunks=NUM_CHUNKS,
        guidance_scale=GUIDANCE_SCALE,
        generator=torch.manual_seed(42),  # ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ
        output_type='trimesh'
    )[0]
    
    time_records['í˜•ìƒ ìƒì„±'] = time.time() - start_time
    
    # GPU ë©”ëª¨ë¦¬ ì •ë¦¬
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
    
    print(f"í˜•ìƒ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! (ì†Œìš” ì‹œê°„: {time_records['í˜•ìƒ ìƒì„±']:.2f}ì´ˆ)")
    print(f"  - ìƒì„±ëœ ë©”ì‰¬: {len(mesh.vertices):,}ê°œ ì •ì , {len(mesh.faces):,}ê°œ ë©´")
    
except RuntimeError as e:
    print(f"\nâŒ í˜•ìƒ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    if "cuDNN" in str(e):
        print("\nğŸ’¡ cuDNN ì˜¤ë¥˜ í•´ê²° ë°©ë²•:")
        print("  1. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ì—ì„œ GPUë¥¼ ì‚¬ìš© ì¤‘ì´ë©´ ì¢…ë£Œ")
        print("  2. ì„¤ì • ë‚®ì¶”ê¸°:")
        print("     OCTREE_RESOLUTION = 256")
        print("     NUM_CHUNKS = 10000")
        print("  3. ì‹œìŠ¤í…œ ì¬ë¶€íŒ…")
        print("  4. CUDA Toolkit ë° cuDNN ì¬ì„¤ì¹˜")
    exit(1)

# í˜•ìƒ ìƒì„± íŒŒì´í”„ë¼ì¸ ë©”ëª¨ë¦¬ í•´ì œ (í…ìŠ¤ì²˜ ìƒì„±ì„ ìœ„í•œ ê³µê°„ í™•ë³´)
print("  - Shape íŒŒì´í”„ë¼ì¸ ë©”ëª¨ë¦¬ í•´ì œ ì¤‘...")
del shape_pipeline
if torch.cuda.is_available():
    torch.cuda.empty_cache()
    torch.cuda.synchronize()
print("  âœ“ ë©”ëª¨ë¦¬ í•´ì œ ì™„ë£Œ")
print("=" * 60)

# 3. í…ìŠ¤ì²˜(Texture) ìƒì„± íŒŒì´í”„ë¼ì¸ ë¡œë“œ
print("\ní…ìŠ¤ì²˜ ìƒì„± íŒŒì´í”„ë¼ì¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
start_time = time.time()

# ì¹´ë©”ë¼ ë·° ì„¤ì •
if CAMERA_VIEWS == 'minimal':
    camera_azims = [0, 120, 240]
    camera_elevs = [0, 0, 0]
    view_weights = [1, 0.3, 0.3]
    print(f"  - ì¹´ë©”ë¼ ë·°: ìµœì†Œ (3ë·°, ë§¤ìš° ë¹ ë¦„)")
elif CAMERA_VIEWS == 'fast':
    camera_azims = [0, 90, 180, 270]
    camera_elevs = [0, 0, 0, 0]
    view_weights = [1, 0.1, 0.5, 0.1]
    print(f"  - ì¹´ë©”ë¼ ë·°: ë¹ ë¦„ (4ë·°)")
else:  # standard
    camera_azims = [0, 90, 180, 270, 0, 180]
    camera_elevs = [0, 0, 0, 0, 90, -90]
    view_weights = [1, 0.1, 0.5, 0.1, 0.05, 0.05]
    print(f"  - ì¹´ë©”ë¼ ë·°: í‘œì¤€ (6ë·°)")

# íŒŒì´í”„ë¼ì¸ ì„¤ì •ì„ ìœ„í•œ ì»¤ìŠ¤í…€ config í´ë˜ìŠ¤
class CustomTexGenConfig:
    def __init__(self, light_remover_ckpt_path, multiview_ckpt_path, subfolder_name):
        self.device = 'cuda'
        self.light_remover_ckpt_path = light_remover_ckpt_path
        self.multiview_ckpt_path = multiview_ckpt_path
        self.candidate_camera_azims = camera_azims
        self.candidate_camera_elevs = camera_elevs
        self.candidate_view_weights = view_weights
        self.render_size = RENDER_SIZE
        self.texture_size = TEXTURE_SIZE
        self.delight_inference_steps = DELIGHT_INFERENCE_STEPS
        self.multiview_inference_steps = MULTIVIEW_INFERENCE_STEPS
        self.bake_exp = 4
        self.merge_method = 'fast'
        self.pipe_dict = {'hunyuan3d-paint-v2-0': 'hunyuanpaint', 'hunyuan3d-paint-v2-0-turbo': 'hunyuanpaint-turbo'}
        self.pipe_name = self.pipe_dict[subfolder_name]

# ì›ë˜ config í´ë˜ìŠ¤ë¥¼ ì„ì‹œë¡œ êµì²´
import hy3dgen.texgen.pipelines as texgen_module
original_config = texgen_module.Hunyuan3DTexGenConfig
texgen_module.Hunyuan3DTexGenConfig = CustomTexGenConfig

paint_pipeline = Hunyuan3DPaintPipeline.from_pretrained(
    'tencent/Hunyuan3D-2',
    subfolder='hunyuan3d-paint-v2-0-turbo'
)

# ì›ë˜ config ë³µì›
texgen_module.Hunyuan3DTexGenConfig = original_config

# âš¡ ì¤‘ìš”: í…ìŠ¤ì²˜ ìƒì„± ëª¨ë¸ë“¤ì„ GPUë¡œ ì´ë™ (ì„±ëŠ¥ í–¥ìƒ)
print("  - ëª¨ë¸ì„ GPUë¡œ ì´ë™ ì¤‘...")
paint_pipeline.models['delight_model'].pipeline.to('cuda')
paint_pipeline.models['multiview_model'].pipeline.to('cuda')
paint_pipeline.render.device = torch.device('cuda')

# GPU ìƒíƒœ í™•ì¸
gpu_status_lines = []
gpu_status_lines.append("ğŸ“Š GPU ìƒíƒœ í™•ì¸:")
try:
    delight_device = paint_pipeline.models['delight_model'].pipeline.unet.device
    multiview_device = paint_pipeline.models['multiview_model'].pipeline.unet.device
    gpu_status_lines.append(f"    - delight_model ë””ë°”ì´ìŠ¤: {delight_device}")
    gpu_status_lines.append(f"    - multiview_model ë””ë°”ì´ìŠ¤: {multiview_device}")
except:
    gpu_status_lines.append(f"    - ë””ë°”ì´ìŠ¤ í™•ì¸ ì‹¤íŒ¨ (í•˜ì§€ë§Œ .to('cuda') í˜¸ì¶œì€ ì™„ë£Œë¨)")
gpu_status_lines.append(f"    - render ë””ë°”ì´ìŠ¤: {paint_pipeline.render.device}")
if torch.cuda.is_available():
    gpu_mem = torch.cuda.memory_allocated() / 1024**3
    gpu_mem_reserved = torch.cuda.memory_reserved() / 1024**3
    gpu_status_lines.append(f"    - GPU ë©”ëª¨ë¦¬ ì‚¬ìš©: {gpu_mem:.2f} GB")
    gpu_status_lines.append(f"    - GPU ë©”ëª¨ë¦¬ ì˜ˆì•½: {gpu_mem_reserved:.2f} GB")

# ì½˜ì†”ì— ì¶œë ¥
print("\n  " + "\n  ".join(gpu_status_lines))

time_records['í…ìŠ¤ì²˜ íŒŒì´í”„ë¼ì¸ ë¡œë“œ'] = time.time() - start_time
print(f"\nì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time_records['í…ìŠ¤ì²˜ íŒŒì´í”„ë¼ì¸ ë¡œë“œ']:.2f}ì´ˆ)")

# 4. í…ìŠ¤ì²˜ ìƒì„± (ì •ë©´ ì´ë¯¸ì§€ ì‚¬ìš©)
print("=" * 60)
print("ëª¨ë¸ì— í…ìŠ¤ì²˜ë¥¼ ì…í™ë‹ˆë‹¤...")
print("  - í…ìŠ¤ì²˜ ê¸°ì¤€ ì´ë¯¸ì§€: front (ì •ë©´)")
if torch.cuda.is_available():
    gpu_mem_before = torch.cuda.memory_allocated() / 1024**3
    print(f"  - ì‹œì‘ ì „ GPU ë©”ëª¨ë¦¬: {gpu_mem_before:.2f} GB")

start_time = time.time()
# ì •ë©´ ì´ë¯¸ì§€ë¥¼ í…ìŠ¤ì²˜ ìƒì„±ì˜ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©
reference_image = processed_images.get('front') or list(processed_images.values())[0]
mesh_textured = paint_pipeline(mesh, image=reference_image)
time_records['í…ìŠ¤ì²˜ ìƒì„±'] = time.time() - start_time

# í…ìŠ¤ì²˜ ìƒì„± í”„ë¡œíŒŒì¼ë§ ê²°ê³¼ ì €ì¥
texture_profiling = getattr(paint_pipeline, 'profiling', {})

if torch.cuda.is_available():
    gpu_mem_after = torch.cuda.memory_allocated() / 1024**3
    print(f"  - ì™„ë£Œ í›„ GPU ë©”ëª¨ë¦¬: {gpu_mem_after:.2f} GB (ë³€í™”: {gpu_mem_after - gpu_mem_before:+.2f} GB)")
print(f"í…ìŠ¤ì²˜ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! (ì†Œìš” ì‹œê°„: {time_records['í…ìŠ¤ì²˜ ìƒì„±']:.2f}ì´ˆ)")
print("=" * 60)

# 5. ìµœì¢… ê²°ê³¼ë¬¼ ì €ì¥
print("\nìµœì¢… ê²°ê³¼ë¬¼ì„ ì €ì¥í•©ë‹ˆë‹¤...")
start_time = time.time()
mesh_textured.export(OUTPUT_PATH)
time_records['íŒŒì¼ ì €ì¥'] = time.time() - start_time
print(f"ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {time_records['íŒŒì¼ ì €ì¥']:.2f}ì´ˆ)")

# 6. ì „ì²´ ì†Œìš” ì‹œê°„ ì¶œë ¥
print("\n" + "=" * 60)
print("ğŸ“Š ì²˜ë¦¬ ì‹œê°„ ìš”ì•½")
print("=" * 60)
total_time = time.time() - start_total
for step, elapsed in time_records.items():
    percentage = (elapsed / total_time) * 100
    print(f"  {step:20s}: {elapsed:6.2f}ì´ˆ ({percentage:5.1f}%)")
print("-" * 60)
print(f"  {'ì´ ì†Œìš” ì‹œê°„':20s}: {total_time:6.2f}ì´ˆ")
print("=" * 60)

# 7. ì‚¬ìš©ëœ ì„¤ì •ê°’ ì¶œë ¥
print("\n" + "=" * 60)
print("âš™ï¸  ì‚¬ìš©ëœ ì„¤ì •ê°’")
print("=" * 60)
print(f"  ì…ë ¥ ì´ë¯¸ì§€ ë·°      : {list(processed_images.keys())}")
print(f"  ì¶œë ¥ íŒŒì¼          : {OUTPUT_PATH}")
print(f"  ë°°ê²½ ì œê±°          : {'í™œì„±í™”' if REMOVE_BACKGROUND else 'ë¹„í™œì„±í™”'}")
print("-" * 60)
print("  [ë©€í‹°ë·° í˜•ìƒ ìƒì„±]")
print(f"    ëª¨ë¸              : Hunyuan3D-DiT-v2-mv-Turbo")
print(f"    FlashVDM ìµœì í™”   : {'í™œì„±í™”' if USE_FLASH_VDM else 'ë¹„í™œì„±í™”'}")
print(f"    ì¶”ë¡  ë‹¨ê³„         : {NUM_INFERENCE_STEPS}")
print(f"    Octree í•´ìƒë„     : {OCTREE_RESOLUTION}")
print(f"    ì²­í¬ ìˆ˜           : {NUM_CHUNKS}")
print(f"    ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼    : {GUIDANCE_SCALE}")
print("-" * 60)
print("  [í…ìŠ¤ì²˜ ìƒì„±]")
print(f"    Delight ì¶”ë¡  ë‹¨ê³„ : {DELIGHT_INFERENCE_STEPS}")
print(f"    Multiview ì¶”ë¡  ë‹¨ê³„: {MULTIVIEW_INFERENCE_STEPS}")
print(f"    ì¹´ë©”ë¼ ë·° ëª¨ë“œ     : {CAMERA_VIEWS}")
print(f"    ë Œë” í•´ìƒë„       : {RENDER_SIZE} x {RENDER_SIZE}")
print(f"    í…ìŠ¤ì²˜ í•´ìƒë„      : {TEXTURE_SIZE} x {TEXTURE_SIZE}")
print("=" * 60)
print(f"\nâœ… í…ìŠ¤ì²˜ê°€ ì ìš©ëœ ë©€í‹°ë·° 3D ëª¨ë¸ì´ '{OUTPUT_PATH}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
print("=" * 60)

# 8. ë¡œê·¸ íŒŒì¼ ì €ì¥
log_content = []
log_content.append("=" * 60)
log_content.append("Hunyuan3D-2 ë©€í‹°ë·° 3D ëª¨ë¸ ìƒì„± ë¡œê·¸")
log_content.append("=" * 60)
log_content.append(f"ìƒì„± ì¼ì‹œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
log_content.append("")

# ì…ë ¥ ì •ë³´
log_content.append("=" * 60)
log_content.append("ğŸ“· ì…ë ¥ ë©€í‹°ë·° ì´ë¯¸ì§€")
log_content.append("=" * 60)
for view_name, image_path in INPUT_IMAGES.items():
    if view_name in processed_images:
        log_content.append(f"  âœ“ {view_name:10s}: {image_path}")
    else:
        log_content.append(f"  âœ— {view_name:10s}: {image_path} (ê±´ë„ˆëœ€)")
log_content.append("=" * 60)
log_content.append("")

# GPU ìƒíƒœ ì •ë³´
log_content.append("=" * 60)
log_content.extend(gpu_status_lines)
log_content.append("=" * 60)
log_content.append("")

# í…ìŠ¤ì²˜ ìƒì„± ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´
if texture_profiling:
    log_content.append("=" * 60)
    log_content.append("ğŸ” í…ìŠ¤ì²˜ ìƒì„± ë‹¨ê³„ë³„ ì‹œê°„ ë¶„ì„")
    log_content.append("=" * 60)
    for step_name, step_time in texture_profiling.items():
        if step_name != 'TOTAL':
            percentage = (step_time / texture_profiling.get('TOTAL', 1)) * 100
            log_content.append(f"  {step_name:25s}: {step_time:7.2f}ì´ˆ ({percentage:5.1f}%)")
    log_content.append("-" * 60)
    log_content.append(f"  {'TOTAL':25s}: {texture_profiling.get('TOTAL', 0):7.2f}ì´ˆ")
    log_content.append("=" * 60)
    log_content.append("")

# ì „ì²´ ì²˜ë¦¬ ì‹œê°„
log_content.append("=" * 60)
log_content.append("ğŸ“Š ì²˜ë¦¬ ì‹œê°„ ìš”ì•½")
log_content.append("=" * 60)
for step, elapsed in time_records.items():
    percentage = (elapsed / total_time) * 100
    log_content.append(f"  {step:20s}: {elapsed:6.2f}ì´ˆ ({percentage:5.1f}%)")
log_content.append("-" * 60)
log_content.append(f"  {'ì´ ì†Œìš” ì‹œê°„':20s}: {total_time:6.2f}ì´ˆ")
log_content.append("=" * 60)
log_content.append("")

# ì„¤ì •ê°’
log_content.append("=" * 60)
log_content.append("âš™ï¸  ì‚¬ìš©ëœ ì„¤ì •ê°’")
log_content.append("=" * 60)
log_content.append(f"  ì…ë ¥ ì´ë¯¸ì§€ ë·°      : {list(processed_images.keys())}")
log_content.append(f"  ì¶œë ¥ íŒŒì¼          : {OUTPUT_PATH}")
log_content.append(f"  ë°°ê²½ ì œê±°          : {'í™œì„±í™”' if REMOVE_BACKGROUND else 'ë¹„í™œì„±í™”'}")
log_content.append("-" * 60)
log_content.append("  [ë©€í‹°ë·° í˜•ìƒ ìƒì„±]")
log_content.append(f"    ëª¨ë¸              : Hunyuan3D-DiT-v2-mv-Turbo")
log_content.append(f"    FlashVDM ìµœì í™”   : {'í™œì„±í™”' if USE_FLASH_VDM else 'ë¹„í™œì„±í™”'}")
log_content.append(f"    ì¶”ë¡  ë‹¨ê³„         : {NUM_INFERENCE_STEPS}")
log_content.append(f"    Octree í•´ìƒë„     : {OCTREE_RESOLUTION}")
log_content.append(f"    ì²­í¬ ìˆ˜           : {NUM_CHUNKS}")
log_content.append(f"    ê°€ì´ë˜ìŠ¤ ìŠ¤ì¼€ì¼    : {GUIDANCE_SCALE}")
log_content.append("-" * 60)
log_content.append("  [í…ìŠ¤ì²˜ ìƒì„±]")
log_content.append(f"    Delight ì¶”ë¡  ë‹¨ê³„ : {DELIGHT_INFERENCE_STEPS}")
log_content.append(f"    Multiview ì¶”ë¡  ë‹¨ê³„: {MULTIVIEW_INFERENCE_STEPS}")
log_content.append(f"    ì¹´ë©”ë¼ ë·° ëª¨ë“œ     : {CAMERA_VIEWS}")
log_content.append(f"    ë Œë” í•´ìƒë„       : {RENDER_SIZE} x {RENDER_SIZE}")
log_content.append(f"    í…ìŠ¤ì²˜ í•´ìƒë„      : {TEXTURE_SIZE} x {TEXTURE_SIZE}")
log_content.append("=" * 60)

with open(LOG_PATH, 'w', encoding='utf-8') as f:
    f.write('\n'.join(log_content))

print(f"\nğŸ“ ë¡œê·¸ íŒŒì¼ì´ '{LOG_PATH}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
